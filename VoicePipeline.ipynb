{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3eIwqtdxnnhk4DDfA/YYK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nattaran/health-tequity-case-nasrin/blob/main/VoicePipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "VRRdbskvhjPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drine"
      ],
      "metadata": {
        "id": "YnZp2fggx-p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCa8NMEGe3_O",
        "outputId": "62468754-8698-4c85-ad96-9154cbf65df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Packages"
      ],
      "metadata": {
        "id": "L1q1opRThsmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/drive/MyDrive/health-tequity-case/requirements.txt\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52n88HN4apZP",
        "outputId": "0f8d696c-fad9-49fc-98ac-1eee850f02e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 15))\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-98zsrgsx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-98zsrgsx\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 8)) (2.6.0+cu124)\n",
            "Requirement already satisfied: openai>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (1.95.1)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 12)) (0.9.0)\n",
            "Collecting ffmpeg-python>=0.2.0 (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 18))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 19)) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (0.11.0)\n",
            "Requirement already satisfied: pydub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 21)) (0.25.1)\n",
            "Collecting jiwer>=3.0.3 (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 24))\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting python-Levenshtein>=0.25.0 (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 25))\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting gtts>=2.3.2 (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 28))\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting deep-translator>=1.11.4 (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 29))\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting python-dotenv>=1.0.1 (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 32))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 33)) (4.67.1)\n",
            "Collecting vosk==0.3.45 (from -r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36))\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk==0.3.45->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36)) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk==0.3.45->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36)) (2.32.3)\n",
            "Collecting srt (from vosk==0.3.45->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36))\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk==0.3.45->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36)) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 12)) (2024.11.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 15)) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 15)) (0.60.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 18)) (1.0.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (1.1.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer>=3.0.3->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 24)) (8.2.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer>=3.0.3->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 24))\n",
            "  Downloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein>=0.25.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 25))\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting click>=8.1.8 (from jiwer>=3.0.3->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 24))\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep-translator>=1.11.4->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 29)) (4.13.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator>=1.11.4->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 29)) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk==0.3.45->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36)) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 15)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (4.3.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.12.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk==0.3.45->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk==0.3.45->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 36)) (2.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.1->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 20)) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->-r /content/drive/MyDrive/health-tequity-case/requirements.txt (line 7)) (3.0.2)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper, srt\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=428cfba90df594b700f0c53a5dad441981a06eddf8b7a8603e25696a8927b39e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e1hict12/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=16b2790d96e0debfc9132a7b7354baf61cc5e6e0319c2438283018264e33e69a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built openai-whisper srt\n",
            "Installing collected packages: srt, rapidfuzz, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ffmpeg-python, click, vosk, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Levenshtein, jiwer, gtts, deep-translator, python-Levenshtein, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load OpenAI API Key (From secretes)"
      ],
      "metadata": {
        "id": "os1Ys4uqh21X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"Add OPENAI_API_KEY in the Secrets panel (left sidebar, key icon).\")"
      ],
      "metadata": {
        "id": "1q-eJA5XgloP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive/health-tequity-case -name \"synthetic_bp_one_person.csv\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVXTOPQ3sj2D",
        "outputId": "7e746e01-91df-484e-f20f-a27c3998ec6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/health-tequity-case/Data/BloodPressure/synthetic_bp_one_person.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Paths and Create Folders"
      ],
      "metadata": {
        "id": "YDlV8BcDiel3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re, pandas as pd, whisper, Levenshtein\n",
        "from openai import OpenAI\n",
        "from jiwer import wer, mer, wil, process_words\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/health-tequity-case\"\n",
        "\n",
        "# --- Define key folders ---\n",
        "AUDIO_INPUT_FOLDER = os.path.join(BASE_PATH, \"Input_Audio_Files\")        # Spanish question audio files\n",
        "AUDIO_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"Data\", \"audio_out\")       # Spanish TTS answers\n",
        "CSV_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"Data\", \"csv_results\")       # WER, CER, SER + pipeline outputs\n",
        "BP_DATA_FOLDER = os.path.join(BASE_PATH, \"Data\", \"BloodPressure\")        # Blood pressure dataset\n",
        "\n",
        "# --- Create required folders if they don’t exist ---\n",
        "for folder in [AUDIO_OUTPUT_FOLDER, CSV_OUTPUT_FOLDER, BP_DATA_FOLDER]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# --- Validate Input Audio Folder ---\n",
        "if not os.path.exists(AUDIO_INPUT_FOLDER):\n",
        "    raise FileNotFoundError(f\"❌ Input folder not found: {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "# --- Collect available audio files ---\n",
        "audio_files = [f for f in os.listdir(AUDIO_INPUT_FOLDER) if f.lower().endswith(('.wav', '.mp3', '.m4a'))]\n",
        "if not audio_files:\n",
        "    raise ValueError(f\"❌ No audio files found in {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "print(f\"✅ Found {len(audio_files)} Spanish audio file(s): {audio_files}\")\n",
        "\n",
        "# --- Blood Pressure dataset check ---\n",
        "csv_path = os.path.join(BP_DATA_FOLDER, \"synthetic_bp_one_person.csv\")\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    print(f\"⚠️ Blood pressure dataset not found at:\\n   {csv_path}\")\n",
        "    print(\"👉 Please upload your synthetic_bp_one_person.csv to this folder before running the pipeline.\")\n",
        "else:\n",
        "    print(f\"✅ Found blood pressure dataset: {csv_path}\")\n",
        "\n",
        "# --- Initialize OpenAI client ---\n",
        "client = OpenAI(api_key=api_key)\n",
        "print(\"✅ OpenAI client initialized successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_EVHBlaiqvt",
        "outputId": "959402cb-bcbf-40c1-8a5a-92a0a8c22413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found 6 Spanish audio file(s): ['q2_es.wav', 'q1_es.wav', 'q4_es.wav', 'q3_es.wav', 'q6_es.wav', 'q5_es.wav']\n",
            "✅ Found blood pressure dataset: /content/drive/MyDrive/health-tequity-case/Data/BloodPressure/synthetic_bp_one_person.csv\n",
            "✅ OpenAI client initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASR Transcrioption Generation Using openAI Whisper Model\n",
        "**Audio -> Transcription -> English Transcription**"
      ],
      "metadata": {
        "id": "RpG5D33plPd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_spanish_audio(model, audio_path):\n",
        "    print(f\"🎧 Transcribing: {audio_path}\")\n",
        "    result = model.transcribe(audio_path, language=\"spanish\", task=\"transcribe\", verbose=False)\n",
        "    return result[\"text\"].strip(), result[\"language\"]\n",
        "\n",
        "def translate_spanish_to_english(spanish_text: str) -> str:\n",
        "    \"\"\"Translate Spanish transcription to English.\"\"\"\n",
        "    prompt = f\"Translate the following Spanish medical question into clear English:\\n\\n{spanish_text}\"\n",
        "    result = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return result.choices[0].message.content.strip()\n",
        "\n",
        "def process_and_translate_audio(audio_folder, audio_files, output_csv):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    all_results = []\n",
        "\n",
        "    print(\"\\n🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\\n\" + \"=\"*60)\n",
        "    for i, audio_file in enumerate(audio_files, 1):\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(f\"⚠️ {audio_file} not found, skipping...\")\n",
        "            continue\n",
        "\n",
        "        spanish_text, detected_lang = transcribe_spanish_audio(model, audio_path)\n",
        "        english_text = translate_spanish_to_english(spanish_text)\n",
        "\n",
        "        all_results.append({\n",
        "            \"audio_file\": audio_file,\n",
        "            \"spanish_transcription\": spanish_text,\n",
        "            \"english_translation\": english_text,\n",
        "            \"language_detected\": detected_lang\n",
        "        })\n",
        "\n",
        "        print(f\"\\n[{i}] {audio_file}\")\n",
        "        print(f\"🇪🇸 {spanish_text}\")\n",
        "        print(f\"🇬🇧 {english_text}\")\n",
        "\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ Transcriptions + translations saved to {output_csv}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "xx4W1fvWlOzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASR Evaluation (WER, CER, SER)\n"
      ],
      "metadata": {
        "id": "S5zy4vfFmzUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cer(reference: str, hypothesis: str) -> float:\n",
        "    reference, hypothesis = reference.strip(), hypothesis.strip()\n",
        "    if not reference:\n",
        "        return 1.0 if hypothesis else 0.0\n",
        "    return Levenshtein.distance(reference, hypothesis) / len(reference)\n",
        "\n",
        "def compute_sentence_error(reference: str, hypothesis: str) -> int:\n",
        "    return 0 if reference.strip() == hypothesis.strip() else 1\n",
        "\n",
        "def evaluate_asr_performance(ground_truth_csv, transcribed_csv, output_csv):\n",
        "    gt_df = pd.read_csv(ground_truth_csv)\n",
        "    tr_df = pd.read_csv(transcribed_csv)\n",
        "    gt_df.columns = [c.lower().strip() for c in gt_df.columns]\n",
        "    tr_df.columns = [c.lower().strip() for c in tr_df.columns]\n",
        "    df = pd.merge(gt_df, tr_df, on=\"audio_file\", how=\"inner\")\n",
        "\n",
        "    results = []\n",
        "    print(f\"\\n🎯 Evaluating {len(df)} files for ASR performance...\\n\")\n",
        "    for _, row in df.iterrows():\n",
        "        ref, hyp = str(row[\"ground_truth\"]), str(row[\"spanish_transcription\"])\n",
        "        m = process_words(ref, hyp)\n",
        "        wer_score = round(m.wer, 4)\n",
        "        subs, dels, ins = m.substitutions, m.deletions, m.insertions\n",
        "        cer = round(compute_cer(ref, hyp), 4)\n",
        "        ser = compute_sentence_error(ref, hyp)\n",
        "        results.append({\n",
        "            \"audio_file\": row[\"audio_file\"],\n",
        "            \"WER\": wer_score, \"Substitutions\": subs,\n",
        "            \"Deletions\": dels, \"Insertions\": ins,\n",
        "            \"CER\": cer, \"SER\": ser\n",
        "        })\n",
        "        print(f\"🎧 {row['audio_file']} → WER: {wer_score}, CER: {cer}, SER: {ser}\")\n",
        "\n",
        "    out_df = pd.DataFrame(results)\n",
        "    out_df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ ASR metrics saved to: {output_csv}\")\n",
        "    return out_df"
      ],
      "metadata": {
        "id": "xkgxrofBmywF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *GPT Data Analysis + Translation + TTS*"
      ],
      "metadata": {
        "id": "1khnwP-9nUzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 3️⃣ GPT DATA ANALYSIS + TRANSLATION + TTS\n",
        "# ================================================================\n",
        "SYSTEM = \"\"\"\n",
        "You are a careful data analyst.\n",
        "You receive a synthetic blood pressure dataset with columns: date, age, sex, systolic, diastolic.\n",
        "Do ALL analysis yourself using ONLY the CSV provided.\n",
        "Answer questions like: daily readings, averages, trends, comparisons, etc.\n",
        "Return JSON:\n",
        "{ \"answer\": \"<English answer>\", \"computed_fields\": { \"numeric values used\" } }\n",
        "\"\"\"\n",
        "\n",
        "def ask_gpt(question_en, csv_block):\n",
        "    user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0,\n",
        "        messages=[{\"role\": \"system\", \"content\": SYSTEM}, {\"role\": \"user\", \"content\": user}]\n",
        "    ).choices[0].message.content\n",
        "    clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M | re.I)\n",
        "    start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "    return json.loads(clean[start:end+1])\n",
        "\n",
        "def translate_to_spanish(english_text):\n",
        "    prompt = f\"Translate this English medical answer into clear, neutral Spanish:\\n{english_text}\"\n",
        "    return client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    ).choices[0].message.content.strip()\n",
        "\n",
        "def text_to_speech_spanish(text, filename, voice=\"alloy\"):\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=\"gpt-4o-mini-tts\", voice=voice, input=text\n",
        "    ) as response:\n",
        "        response.stream_to_file(filename)\n",
        "    print(f\"🔊 Saved Spanish audio: {filename}\")\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "M2ea25UbSSwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main PIPELINE"
      ],
      "metadata": {
        "id": "xpF-SriOtYtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JBPwhCnopGoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 4️⃣ MAIN PIPELINE\n",
        "# ================================================================\n",
        "def run_full_pipeline(csv_path, audio_folder, audio_files):\n",
        "    # Step 1 — Transcribe and Translate Spanish Audio\n",
        "    trans_csv = os.path.join(CSV_OUTPUT_FOLDER, \"audio_translations.csv\")\n",
        "    trans_df = process_and_translate_audio(audio_folder, audio_files, trans_csv)\n",
        "\n",
        "    # Step 2 — Evaluate ASR (WER, CER, SER)\n",
        "    gt_csv = os.path.join(audio_folder, \"ground_truth.csv\")\n",
        "    asr_csv = os.path.join(CSV_OUTPUT_FOLDER, \"asr_metrics.csv\")\n",
        "    asr_df = evaluate_asr_performance(gt_csv, trans_csv, asr_csv)\n",
        "\n",
        "    # Step 3 — Load Blood Pressure Data\n",
        "    df_bp = pd.read_csv(csv_path)\n",
        "    csv_block = df_bp.to_csv(index=False)\n",
        "\n",
        "    results = []\n",
        "    for i, row in trans_df.iterrows():\n",
        "        q_num = i + 1\n",
        "        q_en = row[\"english_translation\"]\n",
        "        print(f\"\\n🔹 Q{q_num}: {q_en}\")\n",
        "\n",
        "        try:\n",
        "            ans = ask_gpt(q_en, csv_block)\n",
        "            ans_en = ans.get(\"answer\", \"\").strip()\n",
        "            ans_es = translate_to_spanish(ans_en)\n",
        "\n",
        "            audio_file = os.path.join(AUDIO_OUTPUT_FOLDER, f\"answer_{q_num}_es.wav\")\n",
        "            text_to_speech_spanish(ans_es, audio_file)\n",
        "\n",
        "            results.append({\n",
        "                \"question_number\": q_num,\n",
        "                \"audio_file_in\": row[\"audio_file\"],\n",
        "                \"spanish_question\": row[\"spanish_transcription\"],\n",
        "                \"english_question\": q_en,\n",
        "                \"english_answer\": ans_en,\n",
        "                \"spanish_answer\": ans_es,\n",
        "                \"audio_answer_file\": audio_file,\n",
        "                \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "            })\n",
        "            print(f\"✅ Completed Q{q_num}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error Q{q_num}: {e}\")\n",
        "\n",
        "    # Step 4 — Save Final Results\n",
        "    final_csv = os.path.join(CSV_OUTPUT_FOLDER, \"final_pipeline_results.csv\")\n",
        "    pd.DataFrame(results).to_csv(final_csv, index=False)\n",
        "    print(f\"\\n✅ All results saved to {final_csv}\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "P-HK0BqWoURC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 5️⃣ RUN\n",
        "# ================================================================\n",
        "csv_path = os.path.join(BASE_PATH, BP_DATA_FOLDER, \"synthetic_bp_one_person.csv\")\n",
        "run_full_pipeline(csv_path, AUDIO_INPUT_FOLDER, audio_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I8pre4voXMI",
        "outputId": "b9327e77-70a0-43f9-fa30-c4a6610e40f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\n",
            "============================================================\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 470/470 [00:01<00:00, 239.29frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] q2_es.wav\n",
            "🇪🇸 ¿Cuáles fueron mis valores de presión arterial durante la última semana?\n",
            "🇬🇧 What were my blood pressure readings over the last week?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 458/458 [00:02<00:00, 224.61frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2] q1_es.wav\n",
            "🇪🇸 ¿Cuáles son mis presiones arteriales histólica y diastólica hoy?\n",
            "🇬🇧 What are my systolic and diastolic blood pressures today?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398/398 [00:01<00:00, 199.18frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3] q4_es.wav\n",
            "🇪🇸 ¿Cuáles son los rango normales para una persona como yo?\n",
            "🇬🇧 What are the normal ranges for someone like me?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 369/369 [00:02<00:00, 182.39frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4] q3_es.wav\n",
            "🇪🇸 ¿Cuál es la tendencia de mis valores de presión arterial?\n",
            "🇬🇧 What is the trend of my blood pressure readings?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q6_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1574/1574 [00:03<00:00, 461.74frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5] q6_es.wav\n",
            "🇪🇸 ¿En qué día mi presión arterial excedió los niveles normales? Compare mi presión arterial promedio en la primera semana y la última semana de este mes. ¿Cuál fue mi presión arterial diastólica más baja este mes?\n",
            "🇬🇧 What day did my blood pressure exceed normal levels? Compare my average blood pressure in the first week and the last week of this month. What was my lowest diastolic blood pressure this month?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q5_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 328/328 [00:01<00:00, 174.11frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6] q5_es.wav\n",
            "🇪🇸 ¿Cuál era mi presión arterial el 10 de octubre?\n",
            "🇬🇧 What was my blood pressure on October 10th?\n",
            "\n",
            "✅ Transcriptions + translations saved to /content/drive/MyDrive/health-tequity-case/Data/csv_results/audio_translations.csv\n",
            "\n",
            "🎯 Evaluating 6 files for ASR performance...\n",
            "\n",
            "🎧 q1_es.wav → WER: 0.1111, CER: 0.0156, SER: 1\n",
            "🎧 q2_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q3_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q4_es.wav → WER: 0.1, CER: 0.0175, SER: 1\n",
            "🎧 q5_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q6_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "\n",
            "✅ ASR metrics saved to: /content/drive/MyDrive/health-tequity-case/Data/csv_results/asr_metrics.csv\n",
            "\n",
            "🔹 Q1: What were my blood pressure readings over the last week?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_1_es.wav\n",
            "✅ Completed Q1\n",
            "\n",
            "🔹 Q2: What are my systolic and diastolic blood pressures today?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_2_es.wav\n",
            "✅ Completed Q2\n",
            "\n",
            "🔹 Q3: What are the normal ranges for someone like me?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_3_es.wav\n",
            "✅ Completed Q3\n",
            "\n",
            "🔹 Q4: What is the trend of my blood pressure readings?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_4_es.wav\n",
            "✅ Completed Q4\n",
            "\n",
            "🔹 Q5: What day did my blood pressure exceed normal levels? Compare my average blood pressure in the first week and the last week of this month. What was my lowest diastolic blood pressure this month?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_5_es.wav\n",
            "✅ Completed Q5\n",
            "\n",
            "🔹 Q6: What was my blood pressure on October 10th?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_6_es.wav\n",
            "✅ Completed Q6\n",
            "\n",
            "✅ All results saved to /content/drive/MyDrive/health-tequity-case/Data/csv_results/final_pipeline_results.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question_number': 1,\n",
              "  'audio_file_in': 'q2_es.wav',\n",
              "  'spanish_question': '¿Cuáles fueron mis valores de presión arterial durante la última semana?',\n",
              "  'english_question': 'What were my blood pressure readings over the last week?',\n",
              "  'english_answer': 'Over the last week, from October 10, 2025, to October 16, 2025, your blood pressure readings were as follows: \\n- October 10: 160/101 mmHg (hypertensive)\\n- October 11: 152/94 mmHg (hypertensive)\\n- October 12: 157/98 mmHg (hypertensive)\\n- October 13: 144/100 mmHg (hypertensive)\\n- October 14: 145/91 mmHg (hypertensive)\\n- October 15: 124/81 mmHg (elevated)\\n- October 16: 110/76 mmHg (normal)',\n",
              "  'spanish_answer': 'Durante la última semana, del 10 de octubre de 2025 al 16 de octubre de 2025, sus lecturas de presión arterial fueron las siguientes:  \\n- 10 de octubre: 160/101 mmHg (hipertensiva)  \\n- 11 de octubre: 152/94 mmHg (hipertensiva)  \\n- 12 de octubre: 157/98 mmHg (hipertensiva)  \\n- 13 de octubre: 144/100 mmHg (hipertensiva)  \\n- 14 de octubre: 145/91 mmHg (hipertensiva)  \\n- 15 de octubre: 124/81 mmHg (elevada)  \\n- 16 de octubre: 110/76 mmHg (normal)',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_1_es.wav',\n",
              "  'computed_fields': '{\"readings\": [{\"date\": \"2025-10-10\", \"systolic\": 160, \"diastolic\": 101, \"category\": \"hypertensive\"}, {\"date\": \"2025-10-11\", \"systolic\": 152, \"diastolic\": 94, \"category\": \"hypertensive\"}, {\"date\": \"2025-10-12\", \"systolic\": 157, \"diastolic\": 98, \"category\": \"hypertensive\"}, {\"date\": \"2025-10-13\", \"systolic\": 144, \"diastolic\": 100, \"category\": \"hypertensive\"}, {\"date\": \"2025-10-14\", \"systolic\": 145, \"diastolic\": 91, \"category\": \"hypertensive\"}, {\"date\": \"2025-10-15\", \"systolic\": 124, \"diastolic\": 81, \"category\": \"elevated\"}, {\"date\": \"2025-10-16\", \"systolic\": 110, \"diastolic\": 76, \"category\": \"normal\"}]}'},\n",
              " {'question_number': 2,\n",
              "  'audio_file_in': 'q1_es.wav',\n",
              "  'spanish_question': '¿Cuáles son mis presiones arteriales histólica y diastólica hoy?',\n",
              "  'english_question': 'What are my systolic and diastolic blood pressures today?',\n",
              "  'english_answer': 'Your systolic blood pressure today, on 2025-10-16, is 110 mmHg and your diastolic blood pressure is 76 mmHg.',\n",
              "  'spanish_answer': 'Tu presión arterial sistólica hoy, 2025-10-16, es de 110 mmHg y tu presión arterial diastólica es de 76 mmHg.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_2_es.wav',\n",
              "  'computed_fields': '{\"systolic_today\": 110, \"diastolic_today\": 76}'},\n",
              " {'question_number': 3,\n",
              "  'audio_file_in': 'q4_es.wav',\n",
              "  'spanish_question': '¿Cuáles son los rango normales para una persona como yo?',\n",
              "  'english_question': 'What are the normal ranges for someone like me?',\n",
              "  'english_answer': \"For a 68-year-old female, normal blood pressure is generally considered to be a systolic reading of less than 120 mmHg and a diastolic reading of less than 80 mmHg. In the dataset, readings categorized as 'normal' fall within these ranges.\",\n",
              "  'spanish_answer': \"Para una mujer de 68 años, la presión arterial normal se considera generalmente una lectura sistólica de menos de 120 mmHg y una lectura diastólica de menos de 80 mmHg. En el conjunto de datos, las lecturas clasificadas como 'normales' están dentro de estos rangos.\",\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_3_es.wav',\n",
              "  'computed_fields': '{\"normal_systolic_range\": \"<120 mmHg\", \"normal_diastolic_range\": \"<80 mmHg\"}'},\n",
              " {'question_number': 4,\n",
              "  'audio_file_in': 'q3_es.wav',\n",
              "  'spanish_question': '¿Cuál es la tendencia de mis valores de presión arterial?',\n",
              "  'english_question': 'What is the trend of my blood pressure readings?',\n",
              "  'english_answer': 'The blood pressure readings show a fluctuating trend with periods of normal and elevated readings interspersed with hypertensive episodes. Initially, from September 17 to September 23, the readings were mostly normal. From September 24 to September 30, there was a significant increase in both systolic and diastolic pressures, indicating a hypertensive phase. This was followed by a return to mostly normal and elevated readings from October 1 to October 7. However, from October 8 to October 14, there was another hypertensive phase. The readings then returned to normal and elevated levels on October 15 and 16.',\n",
              "  'spanish_answer': 'Las lecturas de presión arterial muestran una tendencia fluctuante, con períodos de lecturas normales y elevadas intercaladas con episodios hipertensivos. Inicialmente, desde el 17 de septiembre hasta el 23 de septiembre, la mayoría de las lecturas fueron normales. Desde el 24 de septiembre hasta el 30 de septiembre, hubo un aumento significativo tanto en las presiones sistólica como diastólica, lo que indica una fase hipertensiva. Esto fue seguido por un regreso a lecturas mayormente normales y elevadas del 1 de octubre al 7 de octubre. Sin embargo, desde el 8 de octubre hasta el 14 de octubre, hubo otra fase hipertensiva. Luego, las lecturas volvieron a niveles normales y elevados el 15 y 16 de octubre.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_4_es.wav',\n",
              "  'computed_fields': '{\"normal_periods\": [{\"start\": \"2025-09-17\", \"end\": \"2025-09-23\"}, {\"start\": \"2025-10-01\", \"end\": \"2025-10-07\"}, {\"start\": \"2025-10-15\", \"end\": \"2025-10-16\"}], \"hypertensive_periods\": [{\"start\": \"2025-09-24\", \"end\": \"2025-09-30\"}, {\"start\": \"2025-10-08\", \"end\": \"2025-10-14\"}]}'},\n",
              " {'question_number': 5,\n",
              "  'audio_file_in': 'q6_es.wav',\n",
              "  'spanish_question': '¿En qué día mi presión arterial excedió los niveles normales? Compare mi presión arterial promedio en la primera semana y la última semana de este mes. ¿Cuál fue mi presión arterial diastólica más baja este mes?',\n",
              "  'english_question': 'What day did my blood pressure exceed normal levels? Compare my average blood pressure in the first week and the last week of this month. What was my lowest diastolic blood pressure this month?',\n",
              "  'english_answer': 'Your blood pressure exceeded normal levels on September 18, 2025, when the systolic was 126 mmHg and the diastolic was 70 mmHg, categorized as elevated. In the first week of the dataset (September 17-23, 2025), your average systolic blood pressure was 119.43 mmHg and your average diastolic blood pressure was 75.00 mmHg. In the last week of the dataset (October 10-16, 2025), your average systolic blood pressure was 136.00 mmHg and your average diastolic blood pressure was 89.57 mmHg. The lowest diastolic blood pressure this month was 68 mmHg on October 4, 2025.',\n",
              "  'spanish_answer': 'Su presión arterial superó los niveles normales el 18 de septiembre de 2025, cuando la sistólica fue de 126 mmHg y la diastólica fue de 70 mmHg, categorizándose como elevada. En la primera semana del conjunto de datos (del 17 al 23 de septiembre de 2025), su presión arterial sistólica promedio fue de 119.43 mmHg y su presión arterial diastólica promedio fue de 75.00 mmHg. En la última semana del conjunto de datos (del 10 al 16 de octubre de 2025), su presión arterial sistólica promedio fue de 136.00 mmHg y su presión arterial diastólica promedio fue de 89.57 mmHg. La presión arterial diastólica más baja de este mes fue de 68 mmHg el 4 de octubre de 2025.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_5_es.wav',\n",
              "  'computed_fields': '{\"first_week_average_systolic\": 119.43, \"first_week_average_diastolic\": 75.0, \"last_week_average_systolic\": 136.0, \"last_week_average_diastolic\": 89.57, \"lowest_diastolic\": 68}'},\n",
              " {'question_number': 6,\n",
              "  'audio_file_in': 'q5_es.wav',\n",
              "  'spanish_question': '¿Cuál era mi presión arterial el 10 de octubre?',\n",
              "  'english_question': 'What was my blood pressure on October 10th?',\n",
              "  'english_answer': 'On October 10th, 2025, your blood pressure was 160/101 mmHg.',\n",
              "  'spanish_answer': 'El 10 de octubre de 2025, su presión arterial fue de 160/101 mmHg.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_6_es.wav',\n",
              "  'computed_fields': '{\"systolic\": 160, \"diastolic\": 101}'}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk pydub\n",
        "!apt-get install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI7cACt9atfo",
        "outputId": "3b5e67b3-17a2-48bd-de20-960a939ab7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vosk) (4.67.1)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk) (15.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2025.7.14)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=f6594a699e63fbad5304aa356ec7b23b564851ce9eb227af774137b16d4809bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/vosk_models\n",
        "!wget -q https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip -O /content/vosk_models/vosk-model-small-es.zip\n",
        "!unzip -q /content/vosk_models/vosk-model-small-es.zip -d /content/vosk_models/\n"
      ],
      "metadata": {
        "id": "85rV_KPUyQNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 6️⃣ OUTPUT AUDIO (TTS) ASR EVALUATION USING VOSK\n",
        "# ================================================================\n",
        "import os, json, wave\n",
        "import pandas as pd\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from jiwer import process_words\n",
        "import Levenshtein\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# ================================================================\n",
        "# 🔧 Audio Conversion Helper\n",
        "# ================================================================\n",
        "def convert_to_wav(input_path, output_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Converts any audio file (MP3, M4A, WAV) to mono 16kHz RIFF WAV for Vosk.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(input_path)\n",
        "        audio = audio.set_frame_rate(target_sr).set_channels(1)\n",
        "        audio.export(output_path, format=\"wav\")\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to convert {input_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================================================================\n",
        "# 🔊 Vosk Transcription\n",
        "# ================================================================\n",
        "def transcribe_with_vosk(audio_path, model_path=\"/content/vosk_models/vosk-model-small-es-0.42\"):\n",
        "    \"\"\"\n",
        "    Transcribes a Spanish audio file using Vosk offline ASR model.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(\"❌ Vosk model not found. Please download and unzip it first.\")\n",
        "\n",
        "    model = Model(model_path)\n",
        "    wf = wave.open(audio_path, \"rb\")\n",
        "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() not in [16000, 22050, 44100]:\n",
        "        raise ValueError(f\"⚠️ Unsupported audio format in {audio_path}. Convert to mono 16kHz WAV first.\")\n",
        "\n",
        "    rec = KaldiRecognizer(model, wf.getframerate())\n",
        "    rec.SetWords(True)\n",
        "\n",
        "    result_text = \"\"\n",
        "    while True:\n",
        "        data = wf.readframes(4000)\n",
        "        if len(data) == 0:\n",
        "            break\n",
        "        if rec.AcceptWaveform(data):\n",
        "            part = json.loads(rec.Result())\n",
        "            result_text += part.get(\"text\", \"\") + \" \"\n",
        "    part = json.loads(rec.FinalResult())\n",
        "    result_text += part.get(\"text\", \"\")\n",
        "    wf.close()\n",
        "\n",
        "    return result_text.strip()\n",
        "\n",
        "# ================================================================\n",
        "# 🧮 Evaluate TTS → Text using Vosk ASR\n",
        "# ================================================================\n",
        "def evaluate_output_asr(\n",
        "    tts_csv,\n",
        "    output_csv=os.path.join(CSV_OUTPUT_FOLDER, \"output_asr_metrics.csv\"),\n",
        "    model_path=\"/content/vosk_models/vosk-model-small-es-0.42\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluates TTS Spanish audio output using Vosk ASR model.\n",
        "    Compares transcribed text vs. ground truth Spanish answers.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(tts_csv):\n",
        "        raise FileNotFoundError(f\"❌ Missing final results CSV: {tts_csv}\")\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"❌ Vosk model not found at {model_path}. Download before running.\")\n",
        "\n",
        "    df = pd.read_csv(tts_csv)\n",
        "    results = []\n",
        "\n",
        "    print(\"\\n🎯 Evaluating TTS → Spanish ASR transcription quality\\n\" + \"=\"*60)\n",
        "    for i, row in df.iterrows():\n",
        "        gt = str(row[\"spanish_answer\"])\n",
        "        audio_file = row[\"audio_answer_file\"]\n",
        "        if not os.path.exists(audio_file):\n",
        "            print(f\"⚠️ Missing audio: {audio_file}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Convert to proper WAV\n",
        "            tmp_wav = os.path.join(AUDIO_OUTPUT_FOLDER, f\"tmp_{i}.wav\")\n",
        "            converted_path = convert_to_wav(audio_file, tmp_wav)\n",
        "            if not converted_path:\n",
        "                print(f\"⚠️ Could not convert {audio_file}, skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Transcribe with Vosk\n",
        "            hyp = transcribe_with_vosk(converted_path, model_path)\n",
        "\n",
        "            # Compute metrics\n",
        "            measures = process_words(gt, hyp)\n",
        "            wer_score = round(measures.wer, 4)\n",
        "            subs, dels, ins = measures.substitutions, measures.deletions, measures.insertions\n",
        "            cer = round(Levenshtein.distance(gt, hyp) / max(len(gt), 1), 4)\n",
        "            ser = 0 if gt.strip() == hyp.strip() else 1\n",
        "\n",
        "            results.append({\n",
        "                \"audio_file\": os.path.basename(audio_file),\n",
        "                \"ground_truth\": gt,\n",
        "                \"vosk_transcription\": hyp,\n",
        "                \"WER\": wer_score,\n",
        "                \"Substitutions\": subs,\n",
        "                \"Deletions\": dels,\n",
        "                \"Insertions\": ins,\n",
        "                \"CER\": cer,\n",
        "                \"SER\": ser\n",
        "            })\n",
        "\n",
        "            print(f\"🎧 {os.path.basename(audio_file)} → WER={wer_score}, CER={cer}, SER={ser}\")\n",
        "\n",
        "            # Clean up temp file\n",
        "            os.remove(converted_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing {audio_file}: {e}\")\n",
        "\n",
        "    out_df = pd.DataFrame(results)\n",
        "    out_df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ Output ASR evaluation saved to: {output_csv}\")\n",
        "    return out_df\n"
      ],
      "metadata": {
        "id": "SAGQJVZayiM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your final pipeline results CSV\n",
        "final_results_csv = os.path.join(CSV_OUTPUT_FOLDER, \"final_pipeline_results.csv\")\n",
        "\n",
        "# Run Vosk ASR evaluation on output TTS audios\n",
        "evaluate_output_asr(final_results_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "mQwPyoykynLe",
        "outputId": "0a488818-c437-436e-de6c-0d9d83abe270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Evaluating TTS → Spanish ASR transcription quality\n",
            "============================================================\n",
            "❌ Error processing /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_1_es.wav: file does not start with RIFF id\n",
            "❌ Error processing /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_2_es.wav: file does not start with RIFF id\n",
            "❌ Error processing /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_3_es.wav: file does not start with RIFF id\n",
            "❌ Error processing /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_4_es.wav: file does not start with RIFF id\n",
            "❌ Error processing /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_5_es.wav: file does not start with RIFF id\n",
            "❌ Error processing /content/drive/MyDrive/health-tequity-case/Data/audio_out/answer_6_es.wav: file does not start with RIFF id\n",
            "\n",
            "✅ Output ASR evaluation saved to: /content/drive/MyDrive/health-tequity-case/Data/csv_results/output_asr_metrics.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b6c9ea3-2a06-4ce0-b744-3e866f14fcb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b6c9ea3-2a06-4ce0-b744-3e866f14fcb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b6c9ea3-2a06-4ce0-b744-3e866f14fcb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b6c9ea3-2a06-4ce0-b744-3e866f14fcb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"evaluate_output_asr(final_results_csv)\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Templates + GPT call (JSON output)**"
      ],
      "metadata": {
        "id": "q_Jyz09XejJv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KlQHSNIR3IEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}