{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "authorship_tag": "ABX9TyMdwmKjaQmpIpJN61RS75AZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nattaran/health-tequity-case-nasrin/blob/main/VoicePipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Rx35TvT1uu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive**"
      ],
      "metadata": {
        "id": "SCqyFkqgbMzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk0od9nwapa6",
        "outputId": "4e7e8561-6300-402d-cfc4-00d2c0f19ea8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fZGunFw-bvKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Working Directory**"
      ],
      "metadata": {
        "id": "3Uj2QQHdbvM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Update this path to match your Google Drive folder\n",
        "BASE_DIR = '/content/drive/MyDrive/health-tequity-case'\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# Verify\n",
        "print(f\"✅ Current directory: {os.getcwd()}\")\n",
        "print(f\"📁 Files in directory: {os.listdir('.')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN9RP39Ra-3Q",
        "outputId": "f5e37afb-3323-4179-e1ec-4242b909e60c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Current directory: /content/drive/MyDrive/health-tequity-case\n",
            "📁 Files in directory: ['Input_Audio_Files', 'Output_Audio_Files', 'Data', 'transcriptions_only.gsheet', 'whisper_transcriptions_with_errors.csv', 'transcriptions_only.csv', 'error_rates_summary.csv', 'data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install Required Packages**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HBC5oZPzcJ0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install -q openai-whisper\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q librosa soundfile\n",
        "!pip install -q deep-translator\n",
        "!pip install -q gtts\n",
        "!pip install -q jiwer\n",
        "\n",
        "print(\"✅ All packages installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_KHF0LbXdm7",
        "outputId": "4c03c624-68ee-4344-9f72-e9c6da9a878c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/803.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ All packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries **"
      ],
      "metadata": {
        "id": "IGlBpc6sdTuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from deep_translator import GoogleTranslator\n",
        "from gtts import gTTS\n",
        "import jiwer\n",
        "from jiwer import wer, cer\n",
        "from jiwer import process_words\n",
        "import warnings\n",
        "import torch\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n",
        "\n",
        "# Update this path to match your Google Drive folder\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtBhcDy4UAQW",
        "outputId": "477a25e0-2cdb-46ec-c3c6-75c8f9067a53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accessing to the Spanish Audio Files **"
      ],
      "metadata": {
        "id": "E59WOIEdNK2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AUDIO_FOLDER = '/content/drive/MyDrive/health-tequity-case/Input_Audio_Files/'  # UPDATE THIS\n",
        "\n",
        "# # List all WAV files in the folder\n",
        "# audio_files = sorted([f for f in os.listdir(AUDIO_FOLDER) if f.endswith('.wav')])\n",
        "\n",
        "# print(f\"📁 Found {len(audio_files)} WAV file(s):\")\n",
        "# for filename in audio_files:\n",
        "#     print(f\"  - {filename}\")"
      ],
      "metadata": {
        "id": "Z3LxD_k5ZAEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecb182a-57b1-41cd-cc66-9047978275d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Found 4 WAV file(s):\n",
            "  - q1_es.wav\n",
            "  - q2_es.wav\n",
            "  - q3_es.wav\n",
            "  - q4_es.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GROUND_TRUTH_SPANISH = {\n",
        "#     'q1_es.wav': '¿Cuáles son mis presiones sistólica y diastólica hoy?',\n",
        "#     'q2_es.wav': '¿Cuáles fueron los valores durante la última semana?',\n",
        "#     'q3_es.wav': '¿Cuál es la tendencia de los valores?',\n",
        "#     'q4_es.wav': '¿Cuáles son los rangos normales para una persona como yo?'\n",
        "# }\n",
        "\n",
        "# # Ground truth English translations\n",
        "# # UPDATE THESE with your actual ground truth translations\n",
        "# GROUND_TRUTH_ENGLISH = {\n",
        "#     'question1.wav': 'What are my systolic and diastolic blood pressures today?',\n",
        "#     'question2.wav': 'What were the values over the last week?',\n",
        "#     'question3.wav': 'What is the trend of the values?',\n",
        "#     'question4.wav': 'What are the normal ranges for a person like me?'\n",
        "# }\n",
        "\n",
        "# print(\"\\n✅ Ground truth loaded for error rate calculations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uslBv4vHOcrS",
        "outputId": "e8c5e23a-3794-4aca-fc5e-a2cc8ee9e5a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Ground truth loaded for error rate calculations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3n1Q03i8OqCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load Whisper Model\n",
        "# def load_whisper_model(model_size=\"medium\"):\n",
        "#     \"\"\"\n",
        "#     Load Whisper model for ASR\n",
        "\n",
        "#     Args:\n",
        "#         model_size: 'tiny', 'base', 'small', 'medium', 'large'\n",
        "#                    'medium' recommended for Spanish (good accuracy/speed balance)\n",
        "\n",
        "#     Returns:\n",
        "#         Loaded Whisper model\n",
        "#     \"\"\"\n",
        "#     print(f\"🤖 Loading Whisper '{model_size}' model...\")\n",
        "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#     print(f\"   Device: {device}\")\n",
        "\n",
        "#     model = whisper.load_model(model_size, device=device)\n",
        "#     print(\"✅ Model loaded successfully!\")\n",
        "#     return model\n",
        "\n",
        "# # Load the model\n",
        "# model = load_whisper_model(model_size=\"medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6knv0Q-jOpPD",
        "outputId": "329c908c-0faf-45ee-c34d-0bd95e09053e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Loading Whisper 'medium' model...\n",
            "   Device: cpu\n",
            "✅ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transcription Spanish Audio **"
      ],
      "metadata": {
        "id": "sTv3xZxcPCN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def transcribe_spanish_audio(model, audio_path, task=\"transcribe\"):\n",
        "#     \"\"\"\n",
        "#     Transcribe Spanish audio file using Whisper\n",
        "\n",
        "#     Args:\n",
        "#         model: Loaded Whisper model\n",
        "#         audio_path: Path to WAV file\n",
        "#         task: 'transcribe' (Spanish->Spanish) or 'translate' (Spanish->English)\n",
        "\n",
        "#     Returns:\n",
        "#         Dictionary with transcription results\n",
        "#     \"\"\"\n",
        "#     print(f\"🎵 Processing: {audio_path}\")\n",
        "\n",
        "#     result = model.transcribe(\n",
        "#         audio_path,\n",
        "#         language=\"spanish\",  # Specify Spanish for better accuracy\n",
        "#         task=task,\n",
        "#         verbose=False\n",
        "#     )\n",
        "\n",
        "#     return result\n"
      ],
      "metadata": {
        "id": "z7NEvp3rO8hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Process All Audio Files**"
      ],
      "metadata": {
        "id": "fCQ0r227PnhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_audio_files(model, audio_folder, audio_files):\n",
        "#     \"\"\"\n",
        "#     Process multiple Spanish audio files from Google Drive\n",
        "\n",
        "#     Args:\n",
        "#         model: Loaded Whisper model\n",
        "#         audio_folder: Path to folder containing audio files\n",
        "#         audio_files: List of audio filenames\n",
        "\n",
        "#     Returns:\n",
        "#         DataFrame with transcription results\n",
        "#     \"\"\"\n",
        "#     results = []\n",
        "\n",
        "#     print(\"\\n\" + \"=\"*60)\n",
        "#     print(\"🎯 TRANSCRIBING SPANISH AUDIO FILES\")\n",
        "#     print(\"=\"*60)\n",
        "\n",
        "#     for i, audio_file in enumerate(audio_files, 1):\n",
        "#         audio_path = os.path.join(audio_folder, audio_file)\n",
        "#         print(f\"\\n[{i}/{len(audio_files)}] {audio_file}\")\n",
        "\n",
        "#         if not os.path.exists(audio_path):\n",
        "#             print(f\"⚠️  Warning: {audio_path} not found, skipping...\")\n",
        "#             continue\n",
        "\n",
        "#         # Get Spanish transcription\n",
        "#         spanish_result = transcribe_spanish_audio(model, audio_path, task=\"transcribe\")\n",
        "\n",
        "#         # Get English translation\n",
        "#         english_result = transcribe_spanish_audio(model, audio_path, task=\"translate\")\n",
        "\n",
        "#         results.append({\n",
        "#             'question_number': i,\n",
        "#             'audio_file': audio_file,\n",
        "#             'spanish_transcription': spanish_result['text'].strip(),\n",
        "#             'english_translation': english_result['text'].strip(),\n",
        "#             'language_detected': spanish_result['language']\n",
        "#         })\n",
        "\n",
        "#         print(f\"   🇪🇸 Spanish: {spanish_result['text'].strip()}\")\n",
        "#         print(f\"   🇬🇧 English: {english_result['text'].strip()}\")\n",
        "\n",
        "#     return pd.DataFrame(results)\n",
        "\n",
        "# # Process all files from Google Drive\n",
        "# results_df = process_audio_files(model, AUDIO_FOLDER, audio_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqJbWBB_PbvM",
        "outputId": "c5ac35e7-7606-423c-e067-a697c19f3aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "🎯 TRANSCRIBING SPANISH AUDIO FILES\n",
            "============================================================\n",
            "\n",
            "[1/4] q1_es.wav\n",
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 324/324 [00:29<00:00, 11.15frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 324/324 [00:27<00:00, 11.99frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   🇪🇸 Spanish: ¿Cuáles son mis valores de presión arterial hoy?\n",
            "   🇬🇧 English: What are my blood pressure values today?\n",
            "\n",
            "[2/4] q2_es.wav\n",
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:28<00:00, 11.08frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:29<00:00, 10.65frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   🇪🇸 Spanish: ¿Cuáles fueron los valores de la última semana?\n",
            "   🇬🇧 English: What were the values ​​of the last week?\n",
            "\n",
            "[3/4] q3_es.wav\n",
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [00:30<00:00,  8.47frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [00:28<00:00,  9.05frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   🇪🇸 Spanish: ¿Cuál es la tendencia de mis valores?\n",
            "   🇬🇧 English: What is the trend of my values?\n",
            "\n",
            "[4/4] q4_es.wav\n",
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398/398 [00:29<00:00, 13.44frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎵 Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398/398 [00:28<00:00, 14.21frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   🇪🇸 Spanish: ¿Cuáles son los rangos normales para una persona como yo?\n",
            "   🇬🇧 English: What are the normal ranges for a person like me?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "052sFD6padtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Error Rate Calculation Functions**"
      ],
      "metadata": {
        "id": "1cf4DnjtTxrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def calculate_wer(reference, hypothesis):\n",
        "#     \"\"\"\n",
        "#     Calculate Word Error Rate (WER)\n",
        "#     WER = (Substitutions + Deletions + Insertions) / Total Words in Reference\n",
        "\n",
        "#     Args:\n",
        "#         reference: Ground truth text\n",
        "#         hypothesis: Predicted/transcribed text\n",
        "\n",
        "#     Returns:\n",
        "#         WER score (0-1), detailed metrics\n",
        "#     \"\"\"\n",
        "#     # Normalize text (lowercase, strip)\n",
        "#     ref = reference.lower().strip()\n",
        "#     hyp = hypothesis.lower().strip()\n",
        "\n",
        "#     # Calculate WER\n",
        "#     wer_score = wer(ref, hyp)\n",
        "\n",
        "#     # Get detailed measures\n",
        "#     output= process_words(ref, hyp)\n",
        "\n",
        "#     return {\n",
        "#         'wer': wer_score,\n",
        "#         'substitutions': output.substitutions,\n",
        "#         'deletions': output.deletions,\n",
        "#         'insertions': output.insertions,\n",
        "#         'hits': output.hits\n",
        "#     }\n",
        "\n",
        "# def calculate_cer(reference, hypothesis):\n",
        "#     \"\"\"\n",
        "#     Calculate Character Error Rate (CER)\n",
        "#     CER = (Character Substitutions + Deletions + Insertions) / Total Characters\n",
        "\n",
        "#     Args:\n",
        "#         reference: Ground truth text\n",
        "#         hypothesis: Predicted/transcribed text\n",
        "\n",
        "#     Returns:\n",
        "#         CER score (0-1)\n",
        "#     \"\"\"\n",
        "#     ref = reference.lower().strip()\n",
        "#     hyp = hypothesis.lower().strip()\n",
        "\n",
        "#     cer_score = cer(ref, hyp)\n",
        "#     return cer_score\n",
        "\n",
        "# def calculate_ser(reference, hypothesis):\n",
        "#     \"\"\"\n",
        "#     Calculate Sentence Error Rate (SER)\n",
        "#     SER = 1 if sentences don't match exactly, 0 if they match\n",
        "\n",
        "#     Args:\n",
        "#         reference: Ground truth text\n",
        "#         hypothesis: Predicted/transcribed text\n",
        "\n",
        "#     Returns:\n",
        "#         SER score (0 or 1)\n",
        "#     \"\"\"\n",
        "#     # Normalize for comparison\n",
        "#     ref = reference.lower().strip()\n",
        "#     hyp = hypothesis.lower().strip()\n",
        "\n",
        "#     # SER is 0 if exact match, 1 if not\n",
        "#     ser_score = 0 if ref == hyp else 1\n",
        "#     return ser_score\n",
        "\n",
        "# def calculate_all_error_rates(results_df, ground_truth_spanish):\n",
        "#     \"\"\"\n",
        "#     Calculate all error rates for Spanish and English transcriptions\n",
        "\n",
        "#     Args:\n",
        "#         results_df: DataFrame with transcription results\n",
        "#         ground_truth_spanish: Dictionary of ground truth Spanish text\n",
        "#         ground_truth_english: Dictionary of ground truth English text\n",
        "\n",
        "#     Returns:\n",
        "#         DataFrame with error rates\n",
        "#     \"\"\"\n",
        "#     error_rates = []\n",
        "\n",
        "#     for idx, row in results_df.iterrows():\n",
        "#         audio_file = row['audio_file']\n",
        "\n",
        "#         # Spanish error rates (ASR accuracy)\n",
        "#         if audio_file in ground_truth_spanish:\n",
        "#             spanish_gt = ground_truth_spanish[audio_file]\n",
        "#             spanish_hyp = row['spanish_transcription']\n",
        "\n",
        "#             spanish_wer_details = calculate_wer(spanish_gt, spanish_hyp)\n",
        "#             spanish_cer_score = calculate_cer(spanish_gt, spanish_hyp)\n",
        "#             spanish_ser_score = calculate_ser(spanish_gt, spanish_hyp)\n",
        "#         else:\n",
        "#             spanish_wer_details = {'wer': None, 'substitutions': None, 'deletions': None, 'insertions': None, 'hits': None}\n",
        "#             spanish_cer_score = None\n",
        "#             spanish_ser_score = None\n",
        "\n",
        "#         # English error rates (Translation accuracy)\n",
        "#         # if audio_file in ground_truth_english:\n",
        "#         #     english_gt = ground_truth_english[audio_file]\n",
        "#         #     english_hyp = row['english_translation']\n",
        "\n",
        "#         #     english_wer_details = calculate_wer(english_gt, english_hyp)\n",
        "#         #     english_cer_score = calculate_cer(english_gt, english_hyp)\n",
        "#         #     english_ser_score = calculate_ser(english_gt, english_hyp)\n",
        "#         # else:\n",
        "#         #     english_wer_details = {'wer': None, 'substitutions': None, 'deletions': None, 'insertions': None, 'hits': None}\n",
        "#         #     english_cer_score = None\n",
        "#         #     english_ser_score = None\n",
        "\n",
        "#         error_rates.append({\n",
        "#             'question_number': row['question_number'],\n",
        "#             'audio_file': audio_file,\n",
        "\n",
        "#             # Spanish metrics\n",
        "#             'spanish_wer': spanish_wer_details['wer'],\n",
        "#             'spanish_substitutions': spanish_wer_details['substitutions'],\n",
        "#             'spanish_deletions': spanish_wer_details['deletions'],\n",
        "#             'spanish_insertions': spanish_wer_details['insertions'],\n",
        "#             'spanish_cer': spanish_cer_score,\n",
        "#             'spanish_ser': spanish_ser_score,\n",
        "\n",
        "#             # English metrics\n",
        "#             # 'english_wer': english_wer_details['wer'],\n",
        "#             # 'english_substitutions': english_wer_details['substitutions'],\n",
        "#             # 'english_deletions': english_wer_details['deletions'],\n",
        "#             # 'english_insertions': english_wer_details['insertions'],\n",
        "#             # 'english_cer': english_cer_score,\n",
        "#             # 'english_ser': english_ser_score\n",
        "#         })\n",
        "\n",
        "#     return pd.DataFrame(error_rates)\n",
        "\n",
        "# # Calculate error rates\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"📊 CALCULATING ERROR RATES\")\n",
        "# print(\"=\"*60)\n",
        "\n",
        "# error_rates_df = calculate_all_error_rates(results_df, GROUND_TRUTH_SPANISH)\n",
        "\n",
        "# # Merge with original results\n",
        "# full_results_df = results_df.merge(error_rates_df, on=['question_number', 'audio_file'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS7Y16uDP1I5",
        "outputId": "cb14bbb4-83e5-4613-cc96-c2392e9f612d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📊 CALCULATING ERROR RATES\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Results with Error Rates"
      ],
      "metadata": {
        "id": "qNO4IxAfWS-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 7: Display Results with Error Rates\n",
        "# ============================================\n",
        "# display_cols = ['question_number', 'audio_file', 'spanish_wer', 'spanish_cer',\n",
        "#                 'spanish_ser']  #, 'english_wer', 'english_cer', 'english_ser']\n",
        "# print(full_results_df[display_cols].to_string(index=False))\n",
        "\n",
        "# # Calculate averages (skip None values)\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"📈 AVERAGE ERROR RATES\")\n",
        "# print(\"=\"*60)\n",
        "\n",
        "# # Spanish metrics\n",
        "# spanish_wer_mean = full_results_df['spanish_wer'].dropna().mean()\n",
        "# spanish_cer_mean = full_results_df['spanish_cer'].dropna().mean()\n",
        "# spanish_ser_mean = full_results_df['spanish_ser'].dropna().mean()\n",
        "\n",
        "# print(f\"Spanish ASR:\")\n",
        "# if not pd.isna(spanish_wer_mean):\n",
        "#     print(f\"  Average WER: {spanish_wer_mean:.4f} ({spanish_wer_mean*100:.2f}%)\")\n",
        "#     print(f\"  Average CER: {spanish_cer_mean:.4f} ({spanish_cer_mean*100:.2f}%)\")\n",
        "#     print(f\"  Average SER: {spanish_ser_mean:.4f} ({spanish_ser_mean*100:.2f}%)\")\n",
        "# else:\n",
        "#     print(f\"  ⚠️  No ground truth available for Spanish ASR\")\n",
        "\n",
        "# # English metrics\n",
        "# # english_wer_mean = full_results_df['english_wer'].dropna().mean()\n",
        "# # english_cer_mean = full_results_df['english_cer'].dropna().mean()\n",
        "# # english_ser_mean = full_results_df['english_ser'].dropna().mean()\n",
        "\n",
        "# # print(f\"\\nEnglish Translation:\")\n",
        "# # if not pd.isna(english_wer_mean):\n",
        "# #     print(f\"  Average WER: {english_wer_mean:.4f} ({english_wer_mean*100:.2f}%)\")\n",
        "# #     print(f\"  Average CER: {english_cer_mean:.4f} ({english_cer_mean*100:.2f}%)\")\n",
        "# #     print(f\"  Average SER: {english_ser_mean:.4f} ({english_ser_mean*100:.2f}%)\")\n",
        "# # else:\n",
        "# #     print(f\"  ⚠️  No ground truth available for English translation\")\n",
        "\n",
        "# # ============================================\n",
        "# # SAVE RESULTS\n",
        "# # ============================================\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"💾 SAVING RESULTS\")\n",
        "# print(\"=\"*60)\n",
        "\n",
        "# # Save full results with all columns\n",
        "# output_file_full = \"whisper_transcriptions_with_errors.csv\"\n",
        "# full_results_df.to_csv(output_file_full, index=False)\n",
        "# print(f\"✅ Full results saved to: {output_file_full}\")\n",
        "\n",
        "# # Save transcriptions only (simplified)\n",
        "# transcriptions_only = full_results_df[['question_number', 'audio_file',\n",
        "#                                         'spanish_transcription', 'english_translation']].copy()\n",
        "# output_file_transcriptions = \"transcriptions_only.csv\"\n",
        "# transcriptions_only.to_csv(output_file_transcriptions, index=False)\n",
        "# print(f\"✅ Transcriptions only saved to: {output_file_transcriptions}\")\n",
        "\n",
        "# # Save error rates summary\n",
        "# error_summary = full_results_df[['question_number', 'audio_file',\n",
        "#                                   'spanish_wer', 'spanish_cer', 'spanish_ser']].copy()\n",
        "# output_file_errors = \"error_rates_summary.csv\"\n",
        "# error_summary.to_csv(output_file_errors, index=False)\n",
        "# print(f\"✅ Error rates summary saved to: {output_file_errors}\")\n",
        "\n",
        "# # Save to Google Drive (if mounted)\n",
        "# try:\n",
        "#     # Try to save to Drive if it's mounted\n",
        "#     drive_output_folder = '/content/drive/MyDrive/health_tequity_results/'\n",
        "#     os.makedirs(drive_output_folder, exist_ok=True)\n",
        "\n",
        "#     full_results_df.to_csv(os.path.join(drive_output_folder, output_file_full), index=False)\n",
        "#     transcriptions_only.to_csv(os.path.join(drive_output_folder, output_file_transcriptions), index=False)\n",
        "#     error_summary.to_csv(os.path.join(drive_output_folder, output_file_errors), index=False)\n",
        "\n",
        "#     print(f\"\\n✅ All files also saved to Google Drive: {drive_output_folder}\")\n",
        "# except:\n",
        "#     print(\"\\n⚠️  Google Drive not mounted - files saved locally only\")\n",
        "\n",
        "# # Download files to your computer\n",
        "# print(\"\\n📥 Download files to your computer:\")\n",
        "# from google.colab import files\n",
        "# files.download(output_file_full)\n",
        "# files.download(output_file_transcriptions)\n",
        "# files.download(output_file_errors)\n",
        "\n",
        "# print(\"\\n✅ All results saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "DBUCBm1nUOdu",
        "outputId": "bfe39888-fcdc-4352-d211-ff6f9236e757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " question_number audio_file  spanish_wer  spanish_cer  spanish_ser\n",
            "               1  q1_es.wav     0.500000     0.452830            1\n",
            "               2  q2_es.wav     0.125000     0.096154            1\n",
            "               3  q3_es.wav     0.142857     0.054054            1\n",
            "               4  q4_es.wav     0.000000     0.000000            0\n",
            "\n",
            "============================================================\n",
            "📈 AVERAGE ERROR RATES\n",
            "============================================================\n",
            "Spanish ASR:\n",
            "  Average WER: 0.1920 (19.20%)\n",
            "  Average CER: 0.1508 (15.08%)\n",
            "  Average SER: 0.7500 (75.00%)\n",
            "\n",
            "============================================================\n",
            "💾 SAVING RESULTS\n",
            "============================================================\n",
            "✅ Full results saved to: whisper_transcriptions_with_errors.csv\n",
            "✅ Transcriptions only saved to: transcriptions_only.csv\n",
            "✅ Error rates summary saved to: error_rates_summary.csv\n",
            "\n",
            "✅ All files also saved to Google Drive: /content/drive/MyDrive/health_tequity_results/\n",
            "\n",
            "📥 Download files to your computer:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33d17cc8-f5e7-488a-a298-8dd829e6e4b2\", \"whisper_transcriptions_with_errors.csv\", 761)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_79a504c9-f414-455f-9891-e09a9642ebde\", \"transcriptions_only.csv\", 487)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85281ef6-0a94-4c10-a002-62eb3e0b1b2e\", \"error_rates_summary.csv\", 216)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ All results saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Results"
      ],
      "metadata": {
        "id": "_99qcHNtWs6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Individual Results with Comparision"
      ],
      "metadata": {
        "id": "NSgaaG_9XEGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"📝 DETAILED TRANSCRIPTIONS WITH GROUND TRUTH COMPARISON\")\n",
        "# print(\"=\"*60)\n",
        "\n",
        "# for idx, row in full_results_df.iterrows():\n",
        "#     print(f\"\\n{'='*60}\")\n",
        "#     print(f\"Question {row['question_number']}: {row['audio_file']}\")\n",
        "#     print(f\"{'='*60}\")\n",
        "\n",
        "#     # Spanish comparison\n",
        "#     print(f\"\\n🇪🇸 SPANISH:\")\n",
        "#     audio_file = row['audio_file']\n",
        "#     if audio_file in GROUND_TRUTH_SPANISH:\n",
        "#         print(f\"  Ground Truth: {GROUND_TRUTH_SPANISH[audio_file]}\")\n",
        "#         print(f\"  Transcribed:  {row['spanish_transcription']}\")\n",
        "\n",
        "#         # Display metrics if available\n",
        "#         if row['spanish_wer'] is not None:\n",
        "#             print(f\"  WER: {row['spanish_wer']:.4f} | CER: {row['spanish_cer']:.4f} | SER: {row['spanish_ser']}\")\n",
        "#             print(f\"  Errors: Subs={row['spanish_substitutions']}, Dels={row['spanish_deletions']}, Ins={row['spanish_insertions']}\")\n",
        "#         else:\n",
        "#             print(f\"  ⚠️  No ground truth available for error calculation\")\n",
        "#     else:\n",
        "#         print(f\"  Transcribed:  {row['spanish_transcription']}\")\n",
        "#         print(f\"  ⚠️  No ground truth available\")\n",
        "\n",
        "#     # # English comparison\n",
        "#     # print(f\"\\n🇬🇧 ENGLISH:\")\n",
        "#     # if audio_file in GROUND_TRUTH_ENGLISH:\n",
        "#     #     print(f\"  Ground Truth: {GROUND_TRUTH_ENGLISH[audio_file]}\")\n",
        "#     #     print(f\"  Translated:   {row['english_translation']}\")\n",
        "\n",
        "#     #     # Display metrics if available\n",
        "#     #     if row['english_wer'] is not None:\n",
        "#     #         print(f\"  WER: {row['english_wer']:.4f} | CER: {row['english_cer']:.4f} | SER: {row['english_ser']}\")\n",
        "#     #         print(f\"  Errors: Subs={row['english_substitutions']}, Dels={row['english_deletions']}, Ins={row['english_insertions']}\")\n",
        "#     #     else:\n",
        "#     #         print(f\"  ⚠️  No ground truth available for error calculation\")\n",
        "#     # else:\n",
        "#     #     print(f\"  Translated:   {row['english_translation']}\")\n",
        "#     #     print(f\"  ⚠️  No ground truth available\")\n",
        "#     print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgSuvBnOXLR6",
        "outputId": "9b1f04c3-310c-4635-d9f3-788688f743fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📝 DETAILED TRANSCRIPTIONS WITH GROUND TRUTH COMPARISON\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Question 1: q1_es.wav\n",
            "============================================================\n",
            "\n",
            "🇪🇸 SPANISH:\n",
            "  Ground Truth: ¿Cuáles son mis presiones sistólica y diastólica hoy?\n",
            "  Transcribed:  ¿Cuáles son mis valores de presión arterial hoy?\n",
            "  WER: 0.5000 | CER: 0.4528 | SER: 1\n",
            "  Errors: Subs=4, Dels=0, Ins=0\n",
            "\n",
            "\n",
            "============================================================\n",
            "Question 2: q2_es.wav\n",
            "============================================================\n",
            "\n",
            "🇪🇸 SPANISH:\n",
            "  Ground Truth: ¿Cuáles fueron los valores durante la última semana?\n",
            "  Transcribed:  ¿Cuáles fueron los valores de la última semana?\n",
            "  WER: 0.1250 | CER: 0.0962 | SER: 1\n",
            "  Errors: Subs=1, Dels=0, Ins=0\n",
            "\n",
            "\n",
            "============================================================\n",
            "Question 3: q3_es.wav\n",
            "============================================================\n",
            "\n",
            "🇪🇸 SPANISH:\n",
            "  Ground Truth: ¿Cuál es la tendencia de los valores?\n",
            "  Transcribed:  ¿Cuál es la tendencia de mis valores?\n",
            "  WER: 0.1429 | CER: 0.0541 | SER: 1\n",
            "  Errors: Subs=1, Dels=0, Ins=0\n",
            "\n",
            "\n",
            "============================================================\n",
            "Question 4: q4_es.wav\n",
            "============================================================\n",
            "\n",
            "🇪🇸 SPANISH:\n",
            "  Ground Truth: ¿Cuáles son los rangos normales para una persona como yo?\n",
            "  Transcribed:  ¿Cuáles son los rangos normales para una persona como yo?\n",
            "  WER: 0.0000 | CER: 0.0000 | SER: 0\n",
            "  Errors: Subs=0, Dels=0, Ins=0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM **part**"
      ],
      "metadata": {
        "id": "GrhFIv4iLMze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers accelerate bitsandbytes sentencepiece einops safetensors\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhwghRtXgFPd",
        "outputId": "1a9d376e-703b-4ab7-bf97-256086e4e455"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "object address  : 0x7cc33a10a680\n",
            "object refcount : 2\n",
            "object type     : 0x9d7580\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: see what Colab gave you\n",
        "!nvidia-smi || true\n",
        "\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRYP59Bua6ai",
        "outputId": "f5fedb86-270f-46e9-82e0-4a569e78f165"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \"openai==1.51.2\" \"httpx==0.27.2\" \"httpcore==1.0.5\" pandas\n"
      ],
      "metadata": {
        "id": "j6k8tLuCbBUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24996051-6d15-4d12-bc6b-6855e71ce7e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/383.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.25.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"Add OPENAI_API_KEY in the Secrets panel (left sidebar, key icon).\")"
      ],
      "metadata": {
        "id": "Ck_XFBifbLES"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the CSV from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "csv_path = \"/content/drive/MyDrive/health-tequity-case/Data/synthetic_bp_one_person.csv\""
      ],
      "metadata": {
        "id": "BN8OgxmIdIKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d977865-f47f-47d6-a1cf-0a83e3a5f758"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV as plain text\n",
        "# csv_text = open(CSV_PATH, \"r\", encoding=\"utf-8\").read()\n",
        "# print(\"\\n\".join(csv_text.splitlines()[:5]))\n",
        "\n"
      ],
      "metadata": {
        "id": "8XFXdNOPeVDl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade openai\n"
      ],
      "metadata": {
        "id": "mHT6_L4_DSX2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# STEP: Answer questions + Translate + Save\n",
        "# ======================================\n",
        "# import json, re, pandas as pd, os\n",
        "# from openai import OpenAI\n",
        "\n",
        "# # Initialize client\n",
        "# # client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "# client = OpenAI(api_key=api_key)\n",
        "# # ==========================\n",
        "# # Templates and System Prompt (same as before)\n",
        "# # ==========================\n",
        "# TEMPLATES = {\n",
        "#     \"today\":         \"Your systolic blood pressure was {sys} mm of Hg and your diastolic blood pressure was {dia} mm of Hg.\",\n",
        "#     \"last_week\":     \"Over the last week, your systolic blood pressure has averaged {sys_avg} mm of Hg and your diastolic blood pressure has averaged {dia_avg} mm of Hg.\",\n",
        "#     \"trend_month\":   \"The trend for the values over the last month has been {trend} average values of your systolic blood pressure and diastolic blood pressure.\",\n",
        "#     \"normal_ranges\": \"While each person’s normal range should be discussed with their physician, literature suggests that for a {sex} aged {age} years, systolic and diastolic blood pressure can typically be expected to be {sys_norm} mm Hg and {dia_norm} mm Hg respectively. This information was retrieved from {reference}.\"\n",
        "# }\n",
        "\n",
        "# SYSTEM = \"\"\"You are a careful data analyst.\n",
        "# Do ALL analysis yourself using ONLY the CSV provided by the user.\n",
        "# Interpret columns: date, age, sex, systolic, diastolic.\n",
        "# - \"Today\" = most recent row by date.\n",
        "# - \"Last week\" = last 7 rows by date (including the most recent).\n",
        "# - \"Trend over the last month\" = last 30 rows; return one of: increasing / decreasing / stable.\n",
        "# - If a specific date is mentioned (e.g., 'on October 1'), return that date’s values if present.\n",
        "# Return STRICT JSON ONLY:\n",
        "# {\n",
        "#  \"template\": \"today\"|\"last_week\"|\"trend_month\"|\"normal_ranges\",\n",
        "#  \"fields\": {...},\n",
        "#  \"final_text\": \"one sentence exactly following the chosen template with mm of Hg units\"\n",
        "# }\n",
        "# No extra prose. JSON only.\n",
        "# \"\"\"\n",
        "\n",
        "# # ==========================\n",
        "# # Core Function: Ask GPT for Answer (English)\n",
        "# # ==========================\n",
        "# def ask_gpt(question_en: str, csv_block: str) -> dict:\n",
        "#     \"\"\"Queries GPT for a structured English answer from CSV.\"\"\"\n",
        "#     user = f\"CSV:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\\n\\nReturn JSON only.\"\n",
        "#     resp = client.chat.completions.create(\n",
        "#         model=\"gpt-4o\",\n",
        "#         temperature=0,\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": SYSTEM},\n",
        "#             {\"role\": \"system\", \"content\": \"Templates:\\n\" + json.dumps(TEMPLATES)},\n",
        "#             {\"role\": \"user\", \"content\": user}\n",
        "#         ]\n",
        "#     ).choices[0].message.content\n",
        "\n",
        "#     # Clean response\n",
        "#     clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M | re.I)\n",
        "#     start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "#     return json.loads(clean[start:end+1])\n",
        "\n",
        "\n",
        "# # ==========================\n",
        "# # Translation Function (English → Spanish)\n",
        "# # ==========================\n",
        "# def translate_to_spanish(english_text: str) -> str:\n",
        "#     \"\"\"Uses GPT-4 to translate an English medical answer into Spanish.\"\"\"\n",
        "#     prompt = f\"\"\"\n",
        "# Translate the following English text into clear, neutral Spanish suitable for a healthcare context.\n",
        "# Do NOT add commentary or explanations.\n",
        "\n",
        "# Text:\n",
        "# {english_text}\n",
        "# \"\"\"\n",
        "#     trans = client.responses.create(model=\"gpt-4o-mini\", input=prompt)\n",
        "#     return trans.output_text.strip()\n",
        "\n",
        "\n",
        "# # ==========================\n",
        "# # Run the Full Pipeline\n",
        "# # ==========================\n",
        "# def run_pipeline(csv_path: str):\n",
        "#     df = pd.read_csv(csv_path)\n",
        "#     csv_block = df.head(50).to_csv(index=False)  # send limited rows for context\n",
        "\n",
        "#     questions = {\n",
        "#         \"q1\": \"What are my systolic and diastolic blood pressures today?\",\n",
        "#         \"q2\": \"What were the values over the last week?\",\n",
        "#         \"q3\": \"What is the trend of the values?\",\n",
        "#         \"q4\": \"What are the normal ranges for a person like me?\",\n",
        "#         \"q5\": \"what is my systolic blood pressure on October 10?\"\n",
        "#     }\n",
        "\n",
        "#     results = []\n",
        "#     for qid, qtext in questions.items():\n",
        "#         print(f\"\\n🔹 {qid}: {qtext}\")\n",
        "#         try:\n",
        "#             ans = ask_gpt(qtext, csv_block)\n",
        "#             english = ans.get(\"final_text\", \"\")\n",
        "#             spanish = translate_to_spanish(english)\n",
        "#             results.append({\n",
        "#                 \"question_id\": qid,\n",
        "#                 \"question_en\": qtext,\n",
        "#                 \"answer_en\": english,\n",
        "#                 \"answer_es\": spanish,\n",
        "#                 \"template_used\": ans.get(\"template\", \"\"),\n",
        "#                 \"fields\": json.dumps(ans.get(\"fields\", {}))\n",
        "#             })\n",
        "#             print(f\"✅ Completed {qid}\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ Error in {qid}: {e}\")\n",
        "\n",
        "#     out_df = pd.DataFrame(results)\n",
        "#     os.makedirs(\"data\", exist_ok=True)\n",
        "#     out_df.to_csv(\"/content/drive/MyDrive/health-tequity-case/Data/answers_en_es.csv\", index=False)\n",
        "#     print(\"\\n✅ All results saved to data/answers_en_es.csv\")\n",
        "#     return out_df\n",
        "\n",
        "\n",
        "# # ==========================\n",
        "# # Execute\n",
        "# # ==========================\n",
        "# results_df = run_pipeline(\"/content/drive/MyDrive/health-tequity-case/Data/synthetic_bp_one_person.csv\")\n",
        "# display(results_df)\n"
      ],
      "metadata": {
        "id": "EB_iQZ0T5vGD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Generalized LLM Q&A + Translation Pipeline\n",
        "# ============================================\n",
        "\n",
        "# import json, re, os, pandas as pd\n",
        "# from openai import OpenAI\n",
        "\n",
        "# # Initialize OpenAI client (make sure your .env has OPENAI_API_KEY)\n",
        "# client = OpenAI(api_key=api_key)\n",
        "# # -------------------------------\n",
        "# # 1. Updated System Prompt (Flexible)\n",
        "# # -------------------------------\n",
        "# SYSTEM = \"\"\"\n",
        "# You are a careful data analyst.\n",
        "# You receive a synthetic blood pressure dataset with columns: date, age, sex, systolic, diastolic.\n",
        "\n",
        "# Do ALL analysis yourself using ONLY the CSV data provided by the user.\n",
        "# You may be asked about daily values, weekly averages, monthly trends, minimum/maximum readings, or comparisons by sex or age.\n",
        "\n",
        "# When you answer:\n",
        "# - Perform all calculations directly from the CSV.\n",
        "# - Use precise dates or time windows when mentioned.\n",
        "# - Always include numeric values (in mm Hg).\n",
        "# - Keep your response factual and concise (1–2 sentences).\n",
        "\n",
        "# Return JSON only:\n",
        "# {\n",
        "#  \"answer\": \"<your full English sentence answer>\",\n",
        "#  \"computed_fields\": { \"any intermediate numeric results used\" }\n",
        "# }\n",
        "# \"\"\"\n",
        "\n",
        "# # -------------------------------\n",
        "# # 2. Ask GPT Function\n",
        "# # -------------------------------\n",
        "# def ask_gpt(question_en: str, csv_block: str) -> dict:\n",
        "#     \"\"\"\n",
        "#     Ask GPT-4 to answer any blood pressure–related question using the CSV data.\n",
        "#     Returns a dict with 'answer' and 'computed_fields'.\n",
        "#     \"\"\"\n",
        "#     user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\\n\\nReturn JSON only as specified.\"\n",
        "\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-4o\",  # or gpt-4o-mini for smaller cost\n",
        "#         temperature=0,\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": SYSTEM},\n",
        "#             {\"role\": \"user\", \"content\": user}\n",
        "#         ]\n",
        "#     ).choices[0].message.content\n",
        "\n",
        "#     # Clean the LLM output for JSON safety\n",
        "#     clean = re.sub(r\"^```json|```$\", \"\", response.strip(), flags=re.M | re.I)\n",
        "#     start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "#     return json.loads(clean[start:end+1])\n",
        "\n",
        "\n",
        "# # -------------------------------\n",
        "# # 3. Translation Function (English → Spanish)\n",
        "# # -------------------------------\n",
        "# def translate_to_spanish(english_text: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Uses GPT-4 to translate an English medical answer into clear, neutral Spanish.\n",
        "#     \"\"\"\n",
        "#     prompt = f\"\"\"\n",
        "# Translate the following English medical text into clear, neutral Spanish suitable for a healthcare context.\n",
        "# Do NOT add commentary or explanations.\n",
        "\n",
        "# Text:\n",
        "# {english_text}\n",
        "# \"\"\"\n",
        "#     trans = client.chat.completions.create(\n",
        "#         model=\"gpt-4o-mini\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "#     ).choices[0].message.content.strip()\n",
        "\n",
        "#     return trans\n",
        "\n",
        "\n",
        "# # -------------------------------\n",
        "# # 4. Main Pipeline Function\n",
        "# # -------------------------------\n",
        "# def run_pipeline(csv_path: str, questions: list[str]):\n",
        "#     \"\"\"\n",
        "#     Runs the full LLM + translation pipeline:\n",
        "#     - Reads the dataset\n",
        "#     - Answers each question in English\n",
        "#     - Translates each answer to Spanish\n",
        "#     - Saves results to CSV\n",
        "#     \"\"\"\n",
        "#     df = pd.read_csv(csv_path)\n",
        "#     # Send a subset or the full CSV as text\n",
        "#     csv_block = df.head(50).to_csv(index=False)\n",
        "\n",
        "#     results = []\n",
        "#     for i, q in enumerate(questions, 1):\n",
        "#         print(f\"\\n🔹 Question {i}: {q}\")\n",
        "#         try:\n",
        "#             ans = ask_gpt(q, csv_block)\n",
        "#             english_answer = ans.get(\"answer\", \"\").strip()\n",
        "#             spanish_answer = translate_to_spanish(english_answer)\n",
        "#             results.append({\n",
        "#                 \"question\": q,\n",
        "#                 \"answer_en\": english_answer,\n",
        "#                 \"answer_es\": spanish_answer,\n",
        "#                 \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "#             })\n",
        "#             print(f\"✅ Completed Question {i}\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ Error in Question {i}: {e}\")\n",
        "\n",
        "#     # Save bilingual answers\n",
        "#     os.makedirs(\"data\", exist_ok=True)\n",
        "#     out_df = pd.DataFrame(results)\n",
        "#     out_path = \"/content/drive/MyDrive/health-tequity-case/Data/answers_en_es_october17.csv\"\n",
        "#     out_df.to_csv(out_path, index=False)\n",
        "#     print(f\"\\n✅ All results saved to {out_path}\")\n",
        "#     return out_df\n",
        "\n",
        "\n",
        "# # -------------------------------\n",
        "# # 5. Run the Pipeline\n",
        "# # -------------------------------\n",
        "# # You can pass any question list here\n",
        "# questions = [\n",
        "#     \"What are my systolic and diastolic blood pressures today?\",\n",
        "#     \"What was my average blood pressure over the last two weeks?\",\n",
        "#     \"When was my highest systolic blood pressure recorded?\",\n",
        "#     \"How has my diastolic pressure changed over the last 10 days?\",\n",
        "#     \"What was my blood pressure on October 5th?\",\n",
        "#     \"Compare my average systolic and diastolic pressures for the first and last week.\"\n",
        "# ]\n",
        "\n",
        "# results_df = run_pipeline(\"/content/drive/MyDrive/health-tequity-case/Data/synthetic_bp_one_person.csv\", questions)\n",
        "# display(results_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dp9sXRqeJ7gx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Generalized LLM Q&A + Translation + TTS Pipeline\n",
        "# ============================================\n",
        "\n",
        "# import json, re, os, pandas as pd\n",
        "# from openai import OpenAI\n",
        "\n",
        "# # Initialize OpenAI client\n",
        "# client = OpenAI(api_key=api_key)\n",
        "\n",
        "# # -------------------------------\n",
        "# # 1. Updated System Prompt (Flexible)\n",
        "# # -------------------------------\n",
        "# SYSTEM = \"\"\"\n",
        "# You are a careful data analyst.\n",
        "# You receive a synthetic blood pressure dataset with columns: date, age, sex, systolic, diastolic.\n",
        "\n",
        "# Do ALL analysis yourself using ONLY the CSV data provided by the user.\n",
        "# You may be asked about daily values, weekly averages, monthly trends, minimum/maximum readings, or comparisons by sex or age.\n",
        "\n",
        "# When you answer:\n",
        "# - Perform all calculations directly from the CSV.\n",
        "# - Use precise dates or time windows when mentioned.\n",
        "# - Always include numeric values (in mm Hg).\n",
        "# - Keep your response factual and concise (1–2 sentences).\n",
        "\n",
        "# Return JSON only:\n",
        "# {\n",
        "#  \"answer\": \"<your full English sentence answer>\",\n",
        "#  \"computed_fields\": { \"any intermediate numeric results used\" }\n",
        "# }\n",
        "# \"\"\"\n",
        "\n",
        "# # -------------------------------\n",
        "# # 2. Ask GPT Function\n",
        "# # -------------------------------\n",
        "# def ask_gpt(question_en: str, csv_block: str) -> dict:\n",
        "#     \"\"\"\n",
        "#     Ask GPT-4 to answer any blood pressure–related question using the CSV data.\n",
        "#     Returns a dict with 'answer' and 'computed_fields'.\n",
        "#     \"\"\"\n",
        "#     user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\\n\\nReturn JSON only as specified.\"\n",
        "\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-4o\",\n",
        "#         temperature=0,\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": SYSTEM},\n",
        "#             {\"role\": \"user\", \"content\": user}\n",
        "#         ]\n",
        "#     ).choices[0].message.content\n",
        "\n",
        "#     clean = re.sub(r\"^```json|```$\", \"\", response.strip(), flags=re.M | re.I)\n",
        "#     start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "#     return json.loads(clean[start:end+1])\n",
        "\n",
        "# # -------------------------------\n",
        "# # 3. Translation Function (English → Spanish)\n",
        "# # -------------------------------\n",
        "# def translate_to_spanish(english_text: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Uses GPT-4 to translate an English medical answer into clear, neutral Spanish.\n",
        "#     \"\"\"\n",
        "#     prompt = f\"\"\"\n",
        "# Translate the following English medical text into clear, neutral Spanish suitable for a healthcare context.\n",
        "# Do NOT add commentary or explanations.\n",
        "\n",
        "# Text:\n",
        "# {english_text}\n",
        "# \"\"\"\n",
        "#     trans = client.chat.completions.create(\n",
        "#         model=\"gpt-4o-mini\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "#     ).choices[0].message.content.strip()\n",
        "\n",
        "#     return trans\n",
        "\n",
        "# # -------------------------------\n",
        "# # 4. Text-to-Speech Function (Spanish → Audio)\n",
        "# # -------------------------------\n",
        "# def text_to_speech_spanish(text: str, filename: str, voice: str = \"alloy\"):\n",
        "#     \"\"\"\n",
        "#     Convert Spanish text to spoken audio (.wav) using OpenAI TTS.\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "#         with client.audio.speech.with_streaming_response.create(\n",
        "#             model=\"gpt-4o-mini-tts\",\n",
        "#             voice=voice,\n",
        "#             input=text\n",
        "#         ) as response:\n",
        "#             response.stream_to_file(filename)\n",
        "#         print(f\"🔊 Saved Spanish audio: {filename}\")\n",
        "#         return filename\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ TTS generation failed for '{filename}': {e}\")\n",
        "#         return None\n",
        "\n",
        "# # -------------------------------\n",
        "# # 5. Main Pipeline Function\n",
        "# # -------------------------------\n",
        "# def run_pipeline(csv_path: str, questions: list[str]):\n",
        "#     \"\"\"\n",
        "#     Runs the full LLM + translation + TTS pipeline:\n",
        "#     - Reads the dataset\n",
        "#     - Answers each question in English\n",
        "#     - Translates each answer to Spanish\n",
        "#     - Converts Spanish text to Spanish audio\n",
        "#     - Saves all outputs to CSV\n",
        "#     \"\"\"\n",
        "#     df = pd.read_csv(csv_path)\n",
        "#     csv_block = df.to_csv(index=False)\n",
        "\n",
        "#     results = []\n",
        "#     os.makedirs(\"data/audio\", exist_ok=True)\n",
        "\n",
        "#     for i, q in enumerate(questions, 1):\n",
        "#         print(f\"\\n🔹 Question {i}: {q}\")\n",
        "#         try:\n",
        "#             ans = ask_gpt(q, csv_block)\n",
        "#             english_answer = ans.get(\"answer\", \"\").strip()\n",
        "#             spanish_answer = translate_to_spanish(english_answer)\n",
        "\n",
        "#             # Generate Spanish TTS\n",
        "#             audio_filename = f\"/content/drive/MyDrive/health-tequity-case/Output_Audio_Files/answer_{i}_es.wav\"\n",
        "#             text_to_speech_spanish(spanish_answer, audio_filename)\n",
        "\n",
        "#             results.append({\n",
        "#                 \"question\": q,\n",
        "#                 \"answer_en\": english_answer,\n",
        "#                 \"answer_es\": spanish_answer,\n",
        "#                 \"audio_file\": audio_filename,\n",
        "#                 \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "#             })\n",
        "#             print(f\"✅ Completed Question {i}\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ Error in Question {i}: {e}\")\n",
        "\n",
        "#     # Save all results\n",
        "#     out_df = pd.DataFrame(results)\n",
        "#     out_path = \"/content/drive/MyDrive/health-tequity-case/Data/answers_with_audio_october17.csv\"\n",
        "#     out_df.to_csv(out_path, index=False)\n",
        "#     print(f\"\\n✅ All results (with audio) saved to {out_path}\")\n",
        "#     return out_df\n",
        "\n",
        "# # -------------------------------\n",
        "# # 6. Run the Pipeline\n",
        "# # -------------------------------\n",
        "# questions = [\n",
        "#     \"What are my systolic and diastolic blood pressures today?\",\n",
        "#     \"What was my average blood pressure over the last two weeks?\",\n",
        "#     \"When was my highest systolic blood pressure recorded?\",\n",
        "#     \"How has my diastolic pressure changed over the last 10 days?\",\n",
        "#     \"What was my blood pressure on October 5th?\",\n",
        "#     \"Compare my average systolic and diastolic pressures for the first and last week.\"\n",
        "# ]\n",
        "\n",
        "# results_df = run_pipeline(\"/content/drive/MyDrive/health-tequity-case/Data/synthetic_bp_one_person.csv\", questions)\n",
        "# display(results_df)\n"
      ],
      "metadata": {
        "id": "psHDrAy1RNsw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvhoGvCeSROb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This is the complete pipeline - it has all different steps**"
      ],
      "metadata": {
        "id": "w1pVtmyPauFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# HEALTH TEQUITY CASE – COMPLETE PIPELINE\n",
        "# Audio → Transcription → LLM → Translation → TTS\n",
        "# ============================================\n",
        "\n",
        "import os, json, re, pandas as pd\n",
        "import whisper\n",
        "from openai import OpenAI\n",
        "\n",
        "# ================================================================\n",
        "# 🔧 0️⃣ CONFIGURATION: Define Folder Paths\n",
        "# ================================================================\n",
        "BASE_PATH = \"/content/drive/MyDrive/health-tequity-case\"\n",
        "\n",
        "# Input folder (Spanish audio questions)\n",
        "AUDIO_INPUT_FOLDER = os.path.join(BASE_PATH, \"Input_Audio_Files\")\n",
        "\n",
        "# Output folder for generated Spanish answers (audio)\n",
        "AUDIO_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"audio_out\")\n",
        "\n",
        "# Folder for CSV results (transcriptions + final pipeline output)\n",
        "CSV_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"csv_results\")\n",
        "\n",
        "# Make sure output folders exist\n",
        "os.makedirs(AUDIO_OUTPUT_FOLDER, exist_ok=True)\n",
        "os.makedirs(CSV_OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Check input folder validity\n",
        "if not os.path.exists(AUDIO_INPUT_FOLDER):\n",
        "    raise FileNotFoundError(f\"❌ Input folder not found: {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "audio_files = [f for f in os.listdir(AUDIO_INPUT_FOLDER) if f.lower().endswith(('.wav', '.mp3', '.m4a'))]\n",
        "if not audio_files:\n",
        "    raise ValueError(f\"❌ No audio files found in {AUDIO_INPUT_FOLDER}. Please add Spanish question files.\")\n",
        "\n",
        "print(f\"✅ Using input folder: {AUDIO_INPUT_FOLDER}\")\n",
        "print(f\"✅ Found {len(audio_files)} audio file(s): {audio_files}\")\n",
        "print(f\"📁 Output audio: {AUDIO_OUTPUT_FOLDER}\")\n",
        "print(f\"📁 CSV results: {CSV_OUTPUT_FOLDER}\")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# ================================================================\n",
        "# 1️⃣ AUDIO → SPANISH TRANSCRIPTION → ENGLISH TRANSLATION\n",
        "# ================================================================\n",
        "def transcribe_spanish_audio(model, audio_path):\n",
        "    \"\"\"Transcribe Spanish audio using Whisper.\"\"\"\n",
        "    print(f\"🎧 Transcribing: {audio_path}\")\n",
        "    result = model.transcribe(audio_path, language=\"spanish\", task=\"transcribe\", verbose=False)\n",
        "    return result[\"text\"].strip(), result[\"language\"]\n",
        "\n",
        "def translate_spanish_to_english(spanish_text: str) -> str:\n",
        "    \"\"\"Translate Spanish transcription into English using GPT-4.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "Translate the following Spanish medical question into clear English.\n",
        "Keep it accurate and concise.\n",
        "\n",
        "Text:\n",
        "{spanish_text}\n",
        "\"\"\"\n",
        "    result = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return result.choices[0].message.content.strip()\n",
        "\n",
        "def process_and_translate_audio(audio_folder: str, audio_files: list[str], output_csv: str):\n",
        "    \"\"\"\n",
        "    Transcribe & translate all Spanish audio questions and save CSV.\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
        "    model = whisper.load_model(\"base\")\n",
        "    all_results = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for i, audio_file in enumerate(audio_files, 1):\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        spanish_text, detected_lang = transcribe_spanish_audio(model, audio_path)\n",
        "        english_text = translate_spanish_to_english(spanish_text)\n",
        "\n",
        "        all_results.append({\n",
        "            \"question_number\": i,\n",
        "            \"audio_file\": audio_file,\n",
        "            \"spanish_transcription\": spanish_text,\n",
        "            \"english_translation\": english_text,\n",
        "            \"language_detected\": detected_lang\n",
        "        })\n",
        "\n",
        "        print(f\"\\n[{i}] {audio_file}\")\n",
        "        print(f\"🇪🇸 {spanish_text}\")\n",
        "        print(f\"🇬🇧 {english_text}\")\n",
        "\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ Transcriptions and translations saved to {output_csv}\")\n",
        "    return df\n",
        "\n",
        "# ================================================================\n",
        "# 2️⃣ GPT ANALYSIS + TRANSLATION + TTS\n",
        "# ================================================================\n",
        "SYSTEM = \"\"\"\n",
        "You are a careful data analyst.\n",
        "You receive a synthetic blood pressure dataset with columns: date, age, sex, systolic, diastolic.\n",
        "Do ALL analysis yourself using ONLY the CSV data provided by the user.\n",
        "You may be asked about daily values, weekly averages, monthly trends, min/max readings, or comparisons by sex or age.\n",
        "Return JSON only:\n",
        "{ \"answer\": \"<English text>\", \"computed_fields\": { \"intermediate results\" } }\n",
        "\"\"\"\n",
        "\n",
        "def ask_gpt(question_en: str, csv_block: str) -> dict:\n",
        "    \"\"\"Ask GPT-4 to analyze blood pressure data using an English question.\"\"\"\n",
        "    user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM},\n",
        "            {\"role\": \"user\", \"content\": user}\n",
        "        ]\n",
        "    ).choices[0].message.content\n",
        "    clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M | re.I)\n",
        "    start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "    return json.loads(clean[start:end+1])\n",
        "\n",
        "def translate_to_spanish(english_text: str) -> str:\n",
        "    \"\"\"Translate English medical text to Spanish.\"\"\"\n",
        "    prompt = f\"Translate this English medical text into clear, neutral Spanish:\\n{english_text}\"\n",
        "    return client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    ).choices[0].message.content.strip()\n",
        "\n",
        "def text_to_speech_spanish(text: str, filename: str, voice=\"alloy\"):\n",
        "    \"\"\"Convert Spanish text to speech (TTS).\"\"\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=\"gpt-4o-mini-tts\", voice=voice, input=text\n",
        "    ) as response:\n",
        "        response.stream_to_file(filename)\n",
        "    print(f\"🔊 Saved Spanish audio: {filename}\")\n",
        "    return filename\n",
        "\n",
        "# ================================================================\n",
        "# 3️⃣ MAIN PIPELINE\n",
        "# ================================================================\n",
        "def run_full_pipeline(csv_path: str, audio_folder: str, audio_files: list[str]):\n",
        "    \"\"\"\n",
        "    Full workflow:\n",
        "      1. Transcribe + translate Spanish audio questions\n",
        "      2. Use English translation for GPT-4 analysis\n",
        "      3. Translate answers to Spanish\n",
        "      4. Convert Spanish answers to speech\n",
        "      5. Save all results to CSV\n",
        "    \"\"\"\n",
        "    # Step 1 – Transcription + translation\n",
        "    trans_csv = os.path.join(CSV_OUTPUT_FOLDER, \"audio_translations.csv\")\n",
        "    trans_df = process_and_translate_audio(audio_folder, audio_files, trans_csv)\n",
        "\n",
        "    # Step 2 – Load BP dataset\n",
        "    df_bp = pd.read_csv(csv_path)\n",
        "    csv_block = df_bp.to_csv(index=False)\n",
        "\n",
        "    results = []\n",
        "    for i, row in trans_df.iterrows():\n",
        "        q_num, q_en = row[\"question_number\"], row[\"english_translation\"]\n",
        "        print(f\"\\n🔹 Q{q_num}: {q_en}\")\n",
        "\n",
        "        try:\n",
        "            # Step 3 – GPT Analysis\n",
        "            ans = ask_gpt(q_en, csv_block)\n",
        "            ans_en = ans.get(\"answer\", \"\").strip()\n",
        "\n",
        "            # Step 4 – Translate answer → Spanish\n",
        "            ans_es = translate_to_spanish(ans_en)\n",
        "\n",
        "            # Step 5 – Convert answer → audio\n",
        "            audio_file = os.path.join(AUDIO_OUTPUT_FOLDER, f\"answer_{q_num}_es.wav\")\n",
        "            text_to_speech_spanish(ans_es, audio_file)\n",
        "\n",
        "            results.append({\n",
        "                \"question_number\": q_num,\n",
        "                \"audio_file_in\": row[\"audio_file\"],\n",
        "                \"spanish_question\": row[\"spanish_transcription\"],\n",
        "                \"english_question\": q_en,\n",
        "                \"english_answer\": ans_en,\n",
        "                \"spanish_answer\": ans_es,\n",
        "                \"audio_answer_file\": audio_file,\n",
        "                \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "            })\n",
        "\n",
        "            print(f\"✅ Completed Q{q_num}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error for Q{q_num}: {e}\")\n",
        "\n",
        "    # Step 6 – Save final combined results\n",
        "    final_csv = os.path.join(CSV_OUTPUT_FOLDER, \"final_pipeline_results.csv\")\n",
        "    out_df = pd.DataFrame(results)\n",
        "    out_df.to_csv(final_csv, index=False)\n",
        "    print(f\"\\n✅ All results (audio + translations + analysis) saved to {final_csv}\")\n",
        "    return out_df\n",
        "\n",
        "# ================================================================\n",
        "# 4️⃣ RUN PIPELINE\n",
        "# ================================================================\n",
        "csv_path = os.path.join(BASE_PATH, \"Data\", \"synthetic_bp_one_person.csv\")\n",
        "\n",
        "results_df = run_full_pipeline(csv_path, AUDIO_INPUT_FOLDER, audio_files)\n",
        "display(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aYuCkZmXayh7",
        "outputId": "8b6de21c-c0ff-4db0-fd7f-3d81bd0b9287"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using input folder: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files\n",
            "✅ Found 4 audio file(s): ['q2_es.wav', 'q3_es.wav', 'q4_es.wav', 'q1_es.wav']\n",
            "📁 Output audio: /content/drive/MyDrive/health-tequity-case/data/audio_out\n",
            "📁 CSV results: /content/drive/MyDrive/health-tequity-case/data/csv_results\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 301MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\n",
            "============================================================\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:03<00:00, 98.69frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] q2_es.wav\n",
            "🇪🇸 ¿Cuáles fueron los valores de la última semana?\n",
            "🇬🇧 What were the values from the last week?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [00:02<00:00, 109.18frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2] q3_es.wav\n",
            "🇪🇸 ¿Cuál es la tendencia de mis valores?\n",
            "🇬🇧 What is the trend of my values?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398/398 [00:02<00:00, 141.06frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3] q4_es.wav\n",
            "🇪🇸 ¿Cuáles son los rango normales para una persona como yo?\n",
            "🇬🇧 What are the normal ranges for someone like me?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 324/324 [00:02<00:00, 138.20frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4] q1_es.wav\n",
            "🇪🇸 ¿Cuáles son mis valores de presión arterial hoy?\n",
            "🇬🇧 What are my blood pressure values today?\n",
            "\n",
            "✅ Transcriptions and translations saved to /content/drive/MyDrive/health-tequity-case/data/csv_results/audio_translations.csv\n",
            "\n",
            "🔹 Q1: What were the values from the last week?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_1_es.wav\n",
            "✅ Completed Q1\n",
            "\n",
            "🔹 Q2: What is the trend of my values?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_2_es.wav\n",
            "✅ Completed Q2\n",
            "\n",
            "🔹 Q3: What are the normal ranges for someone like me?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_3_es.wav\n",
            "✅ Completed Q3\n",
            "\n",
            "🔹 Q4: What are my blood pressure values today?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_4_es.wav\n",
            "✅ Completed Q4\n",
            "\n",
            "✅ All results (audio + translations + analysis) saved to /content/drive/MyDrive/health-tequity-case/data/csv_results/final_pipeline_results.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   question_number audio_file_in  \\\n",
              "0                1     q2_es.wav   \n",
              "1                2     q3_es.wav   \n",
              "2                3     q4_es.wav   \n",
              "3                4     q1_es.wav   \n",
              "\n",
              "                                    spanish_question  \\\n",
              "0    ¿Cuáles fueron los valores de la última semana?   \n",
              "1              ¿Cuál es la tendencia de mis valores?   \n",
              "2  ¿Cuáles son los rango normales para una person...   \n",
              "3   ¿Cuáles son mis valores de presión arterial hoy?   \n",
              "\n",
              "                                  english_question  \\\n",
              "0         What were the values from the last week?   \n",
              "1                  What is the trend of my values?   \n",
              "2  What are the normal ranges for someone like me?   \n",
              "3         What are my blood pressure values today?   \n",
              "\n",
              "                                      english_answer  \\\n",
              "0  The blood pressure readings for the last week ...   \n",
              "1  The blood pressure readings show a fluctuating...   \n",
              "2  For a 68-year-old female, normal blood pressur...   \n",
              "3  Your blood pressure values today, on 2025-10-1...   \n",
              "\n",
              "                                      spanish_answer  \\\n",
              "0  Las lecturas de presión arterial de la última ...   \n",
              "1  Las lecturas de presión arterial muestran una ...   \n",
              "2  Para una mujer de 68 años, los rangos normales...   \n",
              "3  Los valores de su presión arterial hoy, 16 de ...   \n",
              "\n",
              "                                   audio_answer_file  \\\n",
              "0  /content/drive/MyDrive/health-tequity-case/dat...   \n",
              "1  /content/drive/MyDrive/health-tequity-case/dat...   \n",
              "2  /content/drive/MyDrive/health-tequity-case/dat...   \n",
              "3  /content/drive/MyDrive/health-tequity-case/dat...   \n",
              "\n",
              "                                     computed_fields  \n",
              "0  {\"2025-10-10\": {\"systolic\": 160, \"diastolic\": ...  \n",
              "1  {\"daily_readings\": {\"2025-09-17\": {\"systolic\":...  \n",
              "2  {\"normal_systolic_range\": \"<120 mmHg\", \"normal...  \n",
              "3  {\"today_date\": \"2025-10-16\", \"today_systolic\":...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74fe46a9-384e-4501-a451-f59dbd34ceed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_number</th>\n",
              "      <th>audio_file_in</th>\n",
              "      <th>spanish_question</th>\n",
              "      <th>english_question</th>\n",
              "      <th>english_answer</th>\n",
              "      <th>spanish_answer</th>\n",
              "      <th>audio_answer_file</th>\n",
              "      <th>computed_fields</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>q2_es.wav</td>\n",
              "      <td>¿Cuáles fueron los valores de la última semana?</td>\n",
              "      <td>What were the values from the last week?</td>\n",
              "      <td>The blood pressure readings for the last week ...</td>\n",
              "      <td>Las lecturas de presión arterial de la última ...</td>\n",
              "      <td>/content/drive/MyDrive/health-tequity-case/dat...</td>\n",
              "      <td>{\"2025-10-10\": {\"systolic\": 160, \"diastolic\": ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>q3_es.wav</td>\n",
              "      <td>¿Cuál es la tendencia de mis valores?</td>\n",
              "      <td>What is the trend of my values?</td>\n",
              "      <td>The blood pressure readings show a fluctuating...</td>\n",
              "      <td>Las lecturas de presión arterial muestran una ...</td>\n",
              "      <td>/content/drive/MyDrive/health-tequity-case/dat...</td>\n",
              "      <td>{\"daily_readings\": {\"2025-09-17\": {\"systolic\":...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>q4_es.wav</td>\n",
              "      <td>¿Cuáles son los rango normales para una person...</td>\n",
              "      <td>What are the normal ranges for someone like me?</td>\n",
              "      <td>For a 68-year-old female, normal blood pressur...</td>\n",
              "      <td>Para una mujer de 68 años, los rangos normales...</td>\n",
              "      <td>/content/drive/MyDrive/health-tequity-case/dat...</td>\n",
              "      <td>{\"normal_systolic_range\": \"&lt;120 mmHg\", \"normal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>q1_es.wav</td>\n",
              "      <td>¿Cuáles son mis valores de presión arterial hoy?</td>\n",
              "      <td>What are my blood pressure values today?</td>\n",
              "      <td>Your blood pressure values today, on 2025-10-1...</td>\n",
              "      <td>Los valores de su presión arterial hoy, 16 de ...</td>\n",
              "      <td>/content/drive/MyDrive/health-tequity-case/dat...</td>\n",
              "      <td>{\"today_date\": \"2025-10-16\", \"today_systolic\":...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74fe46a9-384e-4501-a451-f59dbd34ceed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74fe46a9-384e-4501-a451-f59dbd34ceed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74fe46a9-384e-4501-a451-f59dbd34ceed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-53ffb29b-8467-4631-a539-e332173e79bd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53ffb29b-8467-4631-a539-e332173e79bd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-53ffb29b-8467-4631-a539-e332173e79bd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_01dbb217-9dd1-4b0e-9147-6b55347ffa00\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_01dbb217-9dd1-4b0e-9147-6b55347ffa00 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"question_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_file_in\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"q3_es.wav\",\n          \"q1_es.wav\",\n          \"q2_es.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spanish_question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\u00bfCu\\u00e1l es la tendencia de mis valores?\",\n          \"\\u00bfCu\\u00e1les son mis valores de presi\\u00f3n arterial hoy?\",\n          \"\\u00bfCu\\u00e1les fueron los valores de la \\u00faltima semana?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english_question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"What is the trend of my values?\",\n          \"What are my blood pressure values today?\",\n          \"What were the values from the last week?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"The blood pressure readings show a fluctuating trend over the given period. Initially, from September 17 to September 23, the readings were mostly normal. From September 24 to September 30, there was a period of hypertensive readings. In early October, the readings returned to normal or elevated levels until October 7. From October 8 to October 14, there was another period of hypertensive readings. The readings returned to normal or elevated levels on October 15 and 16.\",\n          \"Your blood pressure values today, on 2025-10-16, are 124 mmHg systolic and 81 mmHg diastolic.\",\n          \"The blood pressure readings for the last week (from 2025-10-10 to 2025-10-16) are as follows: 2025-10-10: 160/101 mmHg, 2025-10-11: 152/94 mmHg, 2025-10-12: 157/98 mmHg, 2025-10-13: 144/100 mmHg, 2025-10-14: 145/91 mmHg, 2025-10-15: 124/81 mmHg, 2025-10-16: 110/76 mmHg.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spanish_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Las lecturas de presi\\u00f3n arterial muestran una tendencia fluctuante durante el periodo indicado. Inicialmente, del 17 de septiembre al 23 de septiembre, las lecturas fueron mayormente normales. Del 24 de septiembre al 30 de septiembre, hubo un periodo de lecturas hipertensivas. A principios de octubre, las lecturas regresaron a niveles normales o elevados hasta el 7 de octubre. Del 8 de octubre al 14 de octubre, hubo otro periodo de lecturas hipertensivas. Las lecturas volvieron a niveles normales o elevados el 15 y 16 de octubre.\",\n          \"Los valores de su presi\\u00f3n arterial hoy, 16 de octubre de 2025, son 124 mmHg sist\\u00f3lica y 81 mmHg diast\\u00f3lica.\",\n          \"Las lecturas de presi\\u00f3n arterial de la \\u00faltima semana (del 10 de octubre de 2025 al 16 de octubre de 2025) son las siguientes: 10 de octubre de 2025: 160/101 mmHg, 11 de octubre de 2025: 152/94 mmHg, 12 de octubre de 2025: 157/98 mmHg, 13 de octubre de 2025: 144/100 mmHg, 14 de octubre de 2025: 145/91 mmHg, 15 de octubre de 2025: 124/81 mmHg, 16 de octubre de 2025: 110/76 mmHg.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_answer_file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"/content/drive/MyDrive/health-tequity-case/data/audio_out/answer_2_es.wav\",\n          \"/content/drive/MyDrive/health-tequity-case/data/audio_out/answer_4_es.wav\",\n          \"/content/drive/MyDrive/health-tequity-case/data/audio_out/answer_1_es.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"computed_fields\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"{\\\"daily_readings\\\": {\\\"2025-09-17\\\": {\\\"systolic\\\": 116, \\\"diastolic\\\": 77, \\\"category\\\": \\\"normal\\\"}, \\\"2025-09-18\\\": {\\\"systolic\\\": 126, \\\"diastolic\\\": 70, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-09-19\\\": {\\\"systolic\\\": 123, \\\"diastolic\\\": 81, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-09-20\\\": {\\\"systolic\\\": 117, \\\"diastolic\\\": 79, \\\"category\\\": \\\"normal\\\"}, \\\"2025-09-21\\\": {\\\"systolic\\\": 115, \\\"diastolic\\\": 71, \\\"category\\\": \\\"normal\\\"}, \\\"2025-09-22\\\": {\\\"systolic\\\": 115, \\\"diastolic\\\": 75, \\\"category\\\": \\\"normal\\\"}, \\\"2025-09-23\\\": {\\\"systolic\\\": 113, \\\"diastolic\\\": 72, \\\"category\\\": \\\"normal\\\"}, \\\"2025-09-24\\\": {\\\"systolic\\\": 140, \\\"diastolic\\\": 93, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-09-25\\\": {\\\"systolic\\\": 150, \\\"diastolic\\\": 85, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-09-26\\\": {\\\"systolic\\\": 147, \\\"diastolic\\\": 90, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-09-27\\\": {\\\"systolic\\\": 140, \\\"diastolic\\\": 86, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-09-28\\\": {\\\"systolic\\\": 147, \\\"diastolic\\\": 98, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-09-29\\\": {\\\"systolic\\\": 138, \\\"diastolic\\\": 91, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-09-30\\\": {\\\"systolic\\\": 161, \\\"diastolic\\\": 98, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-01\\\": {\\\"systolic\\\": 121, \\\"diastolic\\\": 77, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-10-02\\\": {\\\"systolic\\\": 115, \\\"diastolic\\\": 78, \\\"category\\\": \\\"normal\\\"}, \\\"2025-10-03\\\": {\\\"systolic\\\": 118, \\\"diastolic\\\": 81, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-10-04\\\": {\\\"systolic\\\": 120, \\\"diastolic\\\": 68, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-10-05\\\": {\\\"systolic\\\": 113, \\\"diastolic\\\": 75, \\\"category\\\": \\\"normal\\\"}, \\\"2025-10-06\\\": {\\\"systolic\\\": 117, \\\"diastolic\\\": 74, \\\"category\\\": \\\"normal\\\"}, \\\"2025-10-07\\\": {\\\"systolic\\\": 122, \\\"diastolic\\\": 77, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-10-08\\\": {\\\"systolic\\\": 164, \\\"diastolic\\\": 91, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-09\\\": {\\\"systolic\\\": 160, \\\"diastolic\\\": 102, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-10\\\": {\\\"systolic\\\": 160, \\\"diastolic\\\": 101, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-11\\\": {\\\"systolic\\\": 152, \\\"diastolic\\\": 94, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-12\\\": {\\\"systolic\\\": 157, \\\"diastolic\\\": 98, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-13\\\": {\\\"systolic\\\": 144, \\\"diastolic\\\": 100, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-14\\\": {\\\"systolic\\\": 145, \\\"diastolic\\\": 91, \\\"category\\\": \\\"hypertensive\\\"}, \\\"2025-10-15\\\": {\\\"systolic\\\": 124, \\\"diastolic\\\": 81, \\\"category\\\": \\\"elevated\\\"}, \\\"2025-10-16\\\": {\\\"systolic\\\": 110, \\\"diastolic\\\": 76, \\\"category\\\": \\\"normal\\\"}}}\",\n          \"{\\\"today_date\\\": \\\"2025-10-16\\\", \\\"today_systolic\\\": 124, \\\"today_diastolic\\\": 81}\",\n          \"{\\\"2025-10-10\\\": {\\\"systolic\\\": 160, \\\"diastolic\\\": 101}, \\\"2025-10-11\\\": {\\\"systolic\\\": 152, \\\"diastolic\\\": 94}, \\\"2025-10-12\\\": {\\\"systolic\\\": 157, \\\"diastolic\\\": 98}, \\\"2025-10-13\\\": {\\\"systolic\\\": 144, \\\"diastolic\\\": 100}, \\\"2025-10-14\\\": {\\\"systolic\\\": 145, \\\"diastolic\\\": 91}, \\\"2025-10-15\\\": {\\\"systolic\\\": 124, \\\"diastolic\\\": 81}, \\\"2025-10-16\\\": {\\\"systolic\\\": 110, \\\"diastolic\\\": 76}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this pipeline has the WER /CER and sentence error rate computation\n",
        "\n",
        "# ================================================================\n",
        "# HEALTH TEQUITY CASE – COMPLETE PIPELINE\n",
        "# Audio → Transcription → WER → LLM → Translation → TTS\n",
        "# ================================================================\n",
        "\n",
        "import os, json, re, pandas as pd\n",
        "import whisper\n",
        "from openai import OpenAI\n",
        "from jiwer import wer, mer, wil\n",
        "from jiwer import process_words\n",
        "import Levenshtein\n",
        "\n",
        "# ================================================================\n",
        "# 0️⃣ CONFIGURATION\n",
        "# ================================================================\n",
        "BASE_PATH = \"/content/drive/MyDrive/health-tequity-case\"\n",
        "\n",
        "# Define key folders\n",
        "AUDIO_INPUT_FOLDER = os.path.join(BASE_PATH, \"Input_Audio_Files\")\n",
        "AUDIO_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"audio_out\")\n",
        "CSV_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"csv_results\")\n",
        "\n",
        "# Ensure output folders exist\n",
        "os.makedirs(AUDIO_OUTPUT_FOLDER, exist_ok=True)\n",
        "os.makedirs(CSV_OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Check input folder\n",
        "if not os.path.exists(AUDIO_INPUT_FOLDER):\n",
        "    raise FileNotFoundError(f\"❌ Input folder not found: {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "audio_files = [f for f in os.listdir(AUDIO_INPUT_FOLDER) if f.lower().endswith(('.wav', '.mp3', '.m4a'))]\n",
        "if not audio_files:\n",
        "    raise ValueError(f\"❌ No audio files found in {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "print(f\"✅ Found {len(audio_files)} audio file(s): {audio_files}\")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 1️⃣ AUDIO → SPANISH TRANSCRIPTION + ENGLISH TRANSLATION\n",
        "# ================================================================\n",
        "def transcribe_spanish_audio(model, audio_path):\n",
        "    print(f\"🎧 Transcribing: {audio_path}\")\n",
        "    result = model.transcribe(audio_path, language=\"spanish\", task=\"transcribe\", verbose=False)\n",
        "    return result[\"text\"].strip(), result[\"language\"]\n",
        "\n",
        "def translate_spanish_to_english(spanish_text: str) -> str:\n",
        "    \"\"\"Translate Spanish transcription to English.\"\"\"\n",
        "    prompt = f\"Translate the following Spanish medical question into clear English:\\n\\n{spanish_text}\"\n",
        "    result = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return result.choices[0].message.content.strip()\n",
        "\n",
        "def process_and_translate_audio(audio_folder, audio_files, output_csv):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    all_results = []\n",
        "\n",
        "    print(\"\\n🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\\n\" + \"=\"*60)\n",
        "    for i, audio_file in enumerate(audio_files, 1):\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(f\"⚠️ {audio_file} not found, skipping...\")\n",
        "            continue\n",
        "\n",
        "        spanish_text, detected_lang = transcribe_spanish_audio(model, audio_path)\n",
        "        english_text = translate_spanish_to_english(spanish_text)\n",
        "\n",
        "        all_results.append({\n",
        "            \"audio_file\": audio_file,\n",
        "            \"spanish_transcription\": spanish_text,\n",
        "            \"english_translation\": english_text,\n",
        "            \"language_detected\": detected_lang\n",
        "        })\n",
        "\n",
        "        print(f\"\\n[{i}] {audio_file}\")\n",
        "        print(f\"🇪🇸 {spanish_text}\")\n",
        "        print(f\"🇬🇧 {english_text}\")\n",
        "\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ Transcriptions + translations saved to {output_csv}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2️⃣ ASR EVALUATION (WER, CER, SER)\n",
        "# ================================================================\n",
        "\n",
        "# ================================================================\n",
        "# 🧮  ASR EVALUATION: Compute WER, CER, SER for Whisper Transcriptions\n",
        "# ================================================================\n",
        "from jiwer import wer, process_words\n",
        "import Levenshtein\n",
        "\n",
        "def compute_cer(reference: str, hypothesis: str) -> float:\n",
        "    \"\"\"\n",
        "    Compute Character Error Rate (CER) using Levenshtein distance.\n",
        "    CER = edit_distance / len(reference)\n",
        "    \"\"\"\n",
        "    reference, hypothesis = reference.strip(), hypothesis.strip()\n",
        "    if not reference:\n",
        "        return 1.0 if hypothesis else 0.0\n",
        "    return Levenshtein.distance(reference, hypothesis) / len(reference)\n",
        "\n",
        "def compute_sentence_error(reference: str, hypothesis: str) -> int:\n",
        "    \"\"\"\n",
        "    Compute Sentence Error Rate (SER): 0 if identical, 1 otherwise.\n",
        "    \"\"\"\n",
        "    return 0 if reference.strip() == hypothesis.strip() else 1\n",
        "\n",
        "\n",
        "def evaluate_asr_performance(\n",
        "    ground_truth_csv: str,\n",
        "    transcribed_csv: str,\n",
        "    output_csv: str = os.path.join(CSV_OUTPUT_FOLDER, \"asr_metrics.csv\")\n",
        "):\n",
        "    \"\"\"\n",
        "    Compare Whisper-generated transcriptions with ground truth transcriptions.\n",
        "    Compute WER, substitutions, deletions, insertions, CER, and SER.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(ground_truth_csv):\n",
        "        raise FileNotFoundError(f\"❌ Missing GT file: {ground_truth_csv}\")\n",
        "    if not os.path.exists(transcribed_csv):\n",
        "        raise FileNotFoundError(f\"❌ Missing transcription CSV: {transcribed_csv}\")\n",
        "\n",
        "    gt_df = pd.read_csv(ground_truth_csv)\n",
        "    tr_df = pd.read_csv(transcribed_csv)\n",
        "    gt_df.columns = [c.lower().strip() for c in gt_df.columns]\n",
        "    tr_df.columns = [c.lower().strip() for c in tr_df.columns]\n",
        "\n",
        "    df = pd.merge(gt_df, tr_df, on=\"audio_file\", how=\"inner\")\n",
        "    print(f\"\\n🎯 Evaluating {len(df)} audio files for ASR performance...\\n\")\n",
        "\n",
        "    results = []\n",
        "    for i, row in df.iterrows():\n",
        "        ref = str(row[\"ground_truth\"])\n",
        "        hyp = str(row[\"spanish_transcription\"])\n",
        "\n",
        "        # Get detailed WER components using new jiwer API\n",
        "        measures = process_words(ref, hyp)\n",
        "        wer_score = round(measures.wer, 4)\n",
        "        subs = measures.substitutions\n",
        "        dels = measures.deletions\n",
        "        ins = measures.insertions\n",
        "\n",
        "        # Compute CER & SER\n",
        "        cer = round(compute_cer(ref, hyp), 4)\n",
        "        ser = compute_sentence_error(ref, hyp)\n",
        "\n",
        "        results.append({\n",
        "            \"audio_file\": row[\"audio_file\"],\n",
        "            \"ground_truth\": ref,\n",
        "            \"whisper_transcription\": hyp,\n",
        "            \"WER\": wer_score,\n",
        "            \"Substitutions\": subs,\n",
        "            \"Deletions\": dels,\n",
        "            \"Insertions\": ins,\n",
        "            \"CER\": cer,\n",
        "            \"SER\": ser\n",
        "        })\n",
        "\n",
        "        print(f\"🎧 {row['audio_file']} → WER: {wer_score}, CER: {cer}, SER: {ser}\")\n",
        "\n",
        "    out_df = pd.DataFrame(results)\n",
        "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
        "    out_df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ ASR metrics saved to: {output_csv}\")\n",
        "\n",
        "    return out_df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 3️⃣ GPT DATA ANALYSIS + TRANSLATION + TTS\n",
        "# ================================================================\n",
        "SYSTEM = \"\"\"\n",
        "You are a careful data analyst.\n",
        "You receive a synthetic blood pressure dataset with columns: date, age, sex, systolic, diastolic.\n",
        "Do ALL analysis yourself using ONLY the CSV provided.\n",
        "Answer questions like: daily readings, averages, trends, comparisons, etc.\n",
        "Return JSON:\n",
        "{ \"answer\": \"<English answer>\", \"computed_fields\": { \"numeric values used\" } }\n",
        "\"\"\"\n",
        "\n",
        "def ask_gpt(question_en, csv_block):\n",
        "    user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0,\n",
        "        messages=[{\"role\": \"system\", \"content\": SYSTEM}, {\"role\": \"user\", \"content\": user}]\n",
        "    ).choices[0].message.content\n",
        "    clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M | re.I)\n",
        "    start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "    return json.loads(clean[start:end+1])\n",
        "\n",
        "def translate_to_spanish(english_text):\n",
        "    prompt = f\"Translate this English medical answer into clear, neutral Spanish:\\n{english_text}\"\n",
        "    return client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    ).choices[0].message.content.strip()\n",
        "\n",
        "def text_to_speech_spanish(text, filename, voice=\"alloy\"):\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=\"gpt-4o-mini-tts\", voice=voice, input=text\n",
        "    ) as response:\n",
        "        response.stream_to_file(filename)\n",
        "    print(f\"🔊 Saved Spanish audio: {filename}\")\n",
        "    return filename\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 4️⃣ MAIN PIPELINE\n",
        "# ================================================================\n",
        "def run_full_pipeline(csv_path, audio_folder, audio_files):\n",
        "    # Step 1 — Transcribe and Translate Spanish Audio\n",
        "    trans_csv = os.path.join(CSV_OUTPUT_FOLDER, \"audio_translations.csv\")\n",
        "    trans_df = process_and_translate_audio(audio_folder, audio_files, trans_csv)\n",
        "\n",
        "    # Step 2 — Evaluate ASR (WER, CER, SER)\n",
        "    gt_csv = os.path.join(audio_folder, \"ground_truth.csv\")\n",
        "    asr_csv = os.path.join(CSV_OUTPUT_FOLDER, \"asr_metrics.csv\")\n",
        "    asr_df = evaluate_asr_performance(gt_csv, trans_csv, asr_csv)\n",
        "\n",
        "    # Step 3 — Load Blood Pressure Data\n",
        "    df_bp = pd.read_csv(csv_path)\n",
        "    csv_block = df_bp.to_csv(index=False)\n",
        "\n",
        "    results = []\n",
        "    for i, row in trans_df.iterrows():\n",
        "        q_num = i + 1\n",
        "        q_en = row[\"english_translation\"]\n",
        "        print(f\"\\n🔹 Q{q_num}: {q_en}\")\n",
        "\n",
        "        try:\n",
        "            ans = ask_gpt(q_en, csv_block)\n",
        "            ans_en = ans.get(\"answer\", \"\").strip()\n",
        "            ans_es = translate_to_spanish(ans_en)\n",
        "\n",
        "            audio_file = os.path.join(AUDIO_OUTPUT_FOLDER, f\"answer_{q_num}_es.wav\")\n",
        "            text_to_speech_spanish(ans_es, audio_file)\n",
        "\n",
        "            results.append({\n",
        "                \"question_number\": q_num,\n",
        "                \"audio_file_in\": row[\"audio_file\"],\n",
        "                \"spanish_question\": row[\"spanish_transcription\"],\n",
        "                \"english_question\": q_en,\n",
        "                \"english_answer\": ans_en,\n",
        "                \"spanish_answer\": ans_es,\n",
        "                \"audio_answer_file\": audio_file,\n",
        "                \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "            })\n",
        "            print(f\"✅ Completed Q{q_num}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error Q{q_num}: {e}\")\n",
        "\n",
        "    # Step 4 — Save Final Results\n",
        "    final_csv = os.path.join(CSV_OUTPUT_FOLDER, \"final_pipeline_results.csv\")\n",
        "    pd.DataFrame(results).to_csv(final_csv, index=False)\n",
        "    print(f\"\\n✅ All results saved to {final_csv}\")\n",
        "    return results\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 5️⃣ RUN\n",
        "# ================================================================\n",
        "csv_path = os.path.join(BASE_PATH, \"Data\", \"synthetic_bp_one_person.csv\")\n",
        "run_full_pipeline(csv_path, AUDIO_INPUT_FOLDER, audio_files)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2ea25UbSSwm",
        "outputId": "4229a1d5-b6c4-46f5-c6be-8e0728146e82"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found 4 audio file(s): ['q2_es.wav', 'q3_es.wav', 'q4_es.wav', 'q1_es.wav']\n",
            "\n",
            "🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\n",
            "============================================================\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:03<00:00, 85.86frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] q2_es.wav\n",
            "🇪🇸 ¿Cuáles fueron los valores de la última semana?\n",
            "🇬🇧 What were the values from the last week?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [00:02<00:00, 102.02frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2] q3_es.wav\n",
            "🇪🇸 ¿Cuál es la tendencia de mis valores?\n",
            "🇬🇧 What is the trend of my values?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398/398 [00:03<00:00, 102.86frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3] q4_es.wav\n",
            "🇪🇸 ¿Cuáles son los rango normales para una persona como yo?\n",
            "🇬🇧 What are the normal ranges for someone like me?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 324/324 [00:02<00:00, 121.28frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4] q1_es.wav\n",
            "🇪🇸 ¿Cuáles son mis valores de presión arterial hoy?\n",
            "🇬🇧 What are my blood pressure readings today?\n",
            "\n",
            "✅ Transcriptions + translations saved to /content/drive/MyDrive/health-tequity-case/data/csv_results/audio_translations.csv\n",
            "\n",
            "🎯 Evaluating 4 audio files for ASR performance...\n",
            "\n",
            "🎧 q1_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q2_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q3_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q4_es.wav → WER: 0.1, CER: 0.0175, SER: 1\n",
            "\n",
            "✅ ASR metrics saved to: /content/drive/MyDrive/health-tequity-case/data/csv_results/asr_metrics.csv\n",
            "\n",
            "🔹 Q1: What were the values from the last week?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_1_es.wav\n",
            "✅ Completed Q1\n",
            "\n",
            "🔹 Q2: What is the trend of my values?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_2_es.wav\n",
            "✅ Completed Q2\n",
            "\n",
            "🔹 Q3: What are the normal ranges for someone like me?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_3_es.wav\n",
            "✅ Completed Q3\n",
            "\n",
            "🔹 Q4: What are my blood pressure readings today?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/health-tequity-case/data/audio_out/answer_4_es.wav\n",
            "✅ Completed Q4\n",
            "\n",
            "✅ All results saved to /content/drive/MyDrive/health-tequity-case/data/csv_results/final_pipeline_results.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question_number': 1,\n",
              "  'audio_file_in': 'q2_es.wav',\n",
              "  'spanish_question': '¿Cuáles fueron los valores de la última semana?',\n",
              "  'english_question': 'What were the values from the last week?',\n",
              "  'english_answer': 'The blood pressure readings for the last week (from 2025-10-10 to 2025-10-16) are as follows: \\n- 2025-10-10: Systolic 160 mmHg, Diastolic 101 mmHg, Regime hypertensive, Category hypertensive\\n- 2025-10-11: Systolic 152 mmHg, Diastolic 94 mmHg, Regime hypertensive, Category hypertensive\\n- 2025-10-12: Systolic 157 mmHg, Diastolic 98 mmHg, Regime hypertensive, Category hypertensive\\n- 2025-10-13: Systolic 144 mmHg, Diastolic 100 mmHg, Regime hypertensive, Category hypertensive\\n- 2025-10-14: Systolic 145 mmHg, Diastolic 91 mmHg, Regime hypertensive, Category hypertensive\\n- 2025-10-15: Systolic 124 mmHg, Diastolic 81 mmHg, Regime normal, Category elevated\\n- 2025-10-16: Systolic 110 mmHg, Diastolic 76 mmHg, Regime normal, Category normal.',\n",
              "  'spanish_answer': 'Las lecturas de presión arterial de la última semana (del 10 de octubre de 2025 al 16 de octubre de 2025) son las siguientes:  \\n- 10 de octubre de 2025: Sistólica 160 mmHg, Diastólica 101 mmHg, Régimen hipertensivo, Categoría hipertensiva  \\n- 11 de octubre de 2025: Sistólica 152 mmHg, Diastólica 94 mmHg, Régimen hipertensivo, Categoría hipertensiva  \\n- 12 de octubre de 2025: Sistólica 157 mmHg, Diastólica 98 mmHg, Régimen hipertensivo, Categoría hipertensiva  \\n- 13 de octubre de 2025: Sistólica 144 mmHg, Diastólica 100 mmHg, Régimen hipertensivo, Categoría hipertensiva  \\n- 14 de octubre de 2025: Sistólica 145 mmHg, Diastólica 91 mmHg, Régimen hipertensivo, Categoría hipertensiva  \\n- 15 de octubre de 2025: Sistólica 124 mmHg, Diastólica 81 mmHg, Régimen normal, Categoría elevada  \\n- 16 de octubre de 2025: Sistólica 110 mmHg, Diastólica 76 mmHg, Régimen normal, Categoría normal.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/data/audio_out/answer_1_es.wav',\n",
              "  'computed_fields': '{\"2025-10-10\": {\"systolic\": 160, \"diastolic\": 101, \"regime\": \"hypertensive\", \"category\": \"hypertensive\"}, \"2025-10-11\": {\"systolic\": 152, \"diastolic\": 94, \"regime\": \"hypertensive\", \"category\": \"hypertensive\"}, \"2025-10-12\": {\"systolic\": 157, \"diastolic\": 98, \"regime\": \"hypertensive\", \"category\": \"hypertensive\"}, \"2025-10-13\": {\"systolic\": 144, \"diastolic\": 100, \"regime\": \"hypertensive\", \"category\": \"hypertensive\"}, \"2025-10-14\": {\"systolic\": 145, \"diastolic\": 91, \"regime\": \"hypertensive\", \"category\": \"hypertensive\"}, \"2025-10-15\": {\"systolic\": 124, \"diastolic\": 81, \"regime\": \"normal\", \"category\": \"elevated\"}, \"2025-10-16\": {\"systolic\": 110, \"diastolic\": 76, \"regime\": \"normal\", \"category\": \"normal\"}}'},\n",
              " {'question_number': 2,\n",
              "  'audio_file_in': 'q3_es.wav',\n",
              "  'spanish_question': '¿Cuál es la tendencia de mis valores?',\n",
              "  'english_question': 'What is the trend of my values?',\n",
              "  'english_answer': 'The blood pressure readings show a fluctuating trend over the period from September 17, 2025, to October 16, 2025. Initially, the readings are mostly in the normal range, with occasional elevated values. From September 24, 2025, there is a noticeable increase in both systolic and diastolic values, indicating a hypertensive phase that lasts until October 14, 2025. After this period, the readings return to normal or elevated levels. This suggests a temporary period of hypertension followed by a return to more stable readings.',\n",
              "  'spanish_answer': 'Las lecturas de presión arterial muestran una tendencia fluctuante durante el periodo del 17 de septiembre de 2025 al 16 de octubre de 2025. Al principio, las lecturas están mayormente en el rango normal, con valores ocasionalmente elevados. A partir del 24 de septiembre de 2025, hay un aumento notable tanto en los valores sistólicos como diastólicos, lo que indica una fase hipertensiva que dura hasta el 14 de octubre de 2025. Después de este periodo, las lecturas vuelven a niveles normales o elevados. Esto sugiere un periodo temporal de hipertensión seguido de un regreso a lecturas más estables.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/data/audio_out/answer_2_es.wav',\n",
              "  'computed_fields': '{\"normal_period_start\": \"2025-09-17\", \"normal_period_end\": \"2025-09-23\", \"hypertensive_period_start\": \"2025-09-24\", \"hypertensive_period_end\": \"2025-10-14\", \"return_to_normal_start\": \"2025-10-15\", \"return_to_normal_end\": \"2025-10-16\"}'},\n",
              " {'question_number': 3,\n",
              "  'audio_file_in': 'q4_es.wav',\n",
              "  'spanish_question': '¿Cuáles son los rango normales para una persona como yo?',\n",
              "  'english_question': 'What are the normal ranges for someone like me?',\n",
              "  'english_answer': \"For a 68-year-old female, normal blood pressure is generally considered to be a systolic reading of less than 120 mmHg and a diastolic reading of less than 80 mmHg. In the dataset, readings categorized as 'normal' fall within these ranges.\",\n",
              "  'spanish_answer': \"Para una mujer de 68 años, se considera que la presión arterial normal es generalmente una lectura sistólica de menos de 120 mmHg y una lectura diastólica de menos de 80 mmHg. En el conjunto de datos, las lecturas clasificadas como 'normales' se encuentran dentro de estos rangos.\",\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/data/audio_out/answer_3_es.wav',\n",
              "  'computed_fields': '{\"normal_systolic_range\": \"<120 mmHg\", \"normal_diastolic_range\": \"<80 mmHg\"}'},\n",
              " {'question_number': 4,\n",
              "  'audio_file_in': 'q1_es.wav',\n",
              "  'spanish_question': '¿Cuáles son mis valores de presión arterial hoy?',\n",
              "  'english_question': 'What are my blood pressure readings today?',\n",
              "  'english_answer': 'Your blood pressure readings today, on 2025-10-16, are 124 mmHg systolic and 81 mmHg diastolic.',\n",
              "  'spanish_answer': 'Tus lecturas de presión arterial hoy, el 16 de octubre de 2025, son 124 mmHg sistólica y 81 mmHg diastólica.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/health-tequity-case/data/audio_out/answer_4_es.wav',\n",
              "  'computed_fields': '{\"date\": \"2025-10-16\", \"systolic_mmHg\": 124, \"diastolic_mmHg\": 81}'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================\n",
        "# # HEALTH TEQUITY CASE – COMPLETE PIPELINE\n",
        "# # Audio → Transcription → LLM → Translation → TTS\n",
        "# # ============================================\n",
        "\n",
        "# import os, json, re, pandas as pd\n",
        "# import whisper\n",
        "# from openai import OpenAI\n",
        "\n",
        "# # ================================================================\n",
        "# # 🔧 0️⃣ CONFIGURATION: Define Folder Paths\n",
        "# # ================================================================\n",
        "# BASE_PATH = \"/content/drive/MyDrive/health-tequity-case\"\n",
        "\n",
        "# # Input folder (Spanish audio questions)\n",
        "# AUDIO_INPUT_FOLDER = os.path.join(BASE_PATH, \"Input_Audio_Files\")\n",
        "\n",
        "# # Output folder for generated Spanish answers (audio)\n",
        "# AUDIO_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"audio_out\")\n",
        "\n",
        "# # Folder for CSV results (transcriptions + final pipeline output)\n",
        "# CSV_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"csv_results\")\n",
        "\n",
        "# # Make sure output folders exist\n",
        "# os.makedirs(AUDIO_OUTPUT_FOLDER, exist_ok=True)\n",
        "# os.makedirs(CSV_OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# # Check input folder validity\n",
        "# if not os.path.exists(AUDIO_INPUT_FOLDER):\n",
        "#     raise FileNotFoundError(f\"❌ Input folder not found: {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "# audio_files = [f for f in os.listdir(AUDIO_INPUT_FOLDER) if f.lower().endswith(('.wav', '.mp3', '.m4a'))]\n",
        "# if not audio_files:\n",
        "#     raise ValueError(f\"❌ No audio files found in {AUDIO_INPUT_FOLDER}. Please add Spanish question files.\")\n",
        "\n",
        "# print(f\"✅ Using input folder: {AUDIO_INPUT_FOLDER}\")\n",
        "# print(f\"✅ Found {len(audio_files)} audio file(s): {audio_files}\")\n",
        "# print(f\"📁 Output audio: {AUDIO_OUTPUT_FOLDER}\")\n",
        "# print(f\"📁 CSV results: {CSV_OUTPUT_FOLDER}\")\n",
        "\n",
        "# # Initialize OpenAI client\n",
        "# client = OpenAI(api_key=api_key)\n",
        "\n",
        "# # ================================================================\n",
        "# # 1️⃣ AUDIO → SPANISH TRANSCRIPTION → ENGLISH TRANSLATION\n",
        "# # ================================================================\n",
        "# def transcribe_spanish_audio(model, audio_path):\n",
        "#     \"\"\"Transcribe Spanish audio using Whisper.\"\"\"\n",
        "#     print(f\"🎧 Transcribing: {audio_path}\")\n",
        "#     result = model.transcribe(audio_path, language=\"spanish\", task=\"transcribe\", verbose=False)\n",
        "#     return result[\"text\"].strip(), result[\"language\"]\n",
        "\n",
        "# def translate_spanish_to_english(spanish_text: str) -> str:\n",
        "#     \"\"\"Translate Spanish transcription into English using GPT-4.\"\"\"\n",
        "#     prompt = f\"\"\"\n",
        "# Translate the following Spanish medical question into clear English.\n",
        "# Keep it accurate and concise.\n",
        "\n",
        "# Text:\n",
        "# {spanish_text}\n",
        "# \"\"\"\n",
        "#     result = client.chat.completions.create(\n",
        "#         model=\"gpt-4o-mini\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "#     )\n",
        "#     return result.choices[0].message.content.strip()\n",
        "\n",
        "# def process_and_translate_audio(audio_folder: str, audio_files: list[str], output_csv: str):\n",
        "#     \"\"\"\n",
        "#     Transcribe & translate all Spanish audio questions and save CSV.\n",
        "#     \"\"\"\n",
        "#     os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
        "#     model = whisper.load_model(\"base\")\n",
        "#     all_results = []\n",
        "\n",
        "#     print(\"\\n\" + \"=\"*60)\n",
        "#     print(\"🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\")\n",
        "#     print(\"=\"*60)\n",
        "\n",
        "#     for i, audio_file in enumerate(audio_files, 1):\n",
        "#         audio_path = os.path.join(audio_folder, audio_file)\n",
        "#         spanish_text, detected_lang = transcribe_spanish_audio(model, audio_path)\n",
        "#         english_text = translate_spanish_to_english(spanish_text)\n",
        "\n",
        "#         all_results.append({\n",
        "#             \"question_number\": i,\n",
        "#             \"audio_file\": audio_file,\n",
        "#             \"spanish_transcription\": spanish_text,\n",
        "#             \"english_translation\": english_text,\n",
        "#             \"language_detected\": detected_lang\n",
        "#         })\n",
        "\n",
        "#         print(f\"\\n[{i}] {audio_file}\")\n",
        "#         print(f\"🇪🇸 {spanish_text}\")\n",
        "#         print(f\"🇬🇧 {english_text}\")\n",
        "\n",
        "#     df = pd.DataFrame(all_results)\n",
        "#     df.to_csv(output_csv, index=False)\n",
        "#     print(f\"\\n✅ Transcriptions and translations saved to {output_csv}\")\n",
        "#     return df\n",
        "\n",
        "# # ================================================================\n",
        "# # 2️⃣ GPT ANALYSIS + TRANSLATION + TTS\n",
        "# # ================================================================\n",
        "# SYSTEM = \"\"\"\n",
        "# You are a careful data analyst.\n",
        "# You receive a synthetic blood pressure dataset with columns: date, age, sex, systolic, diastolic.\n",
        "# Do ALL analysis yourself using ONLY the CSV data provided by the user.\n",
        "# You may be asked about daily values, weekly averages, monthly trends, min/max readings, or comparisons by sex or age.\n",
        "# Return JSON only:\n",
        "# { \"answer\": \"<English text>\", \"computed_fields\": { \"intermediate results\" } }\n",
        "# \"\"\"\n",
        "\n",
        "# def ask_gpt(question_en: str, csv_block: str) -> dict:\n",
        "#     \"\"\"Ask GPT-4 to analyze blood pressure data using an English question.\"\"\"\n",
        "#     user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\"\n",
        "#     resp = client.chat.completions.create(\n",
        "#         model=\"gpt-4o\",\n",
        "#         temperature=0,\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": SYSTEM},\n",
        "#             {\"role\": \"user\", \"content\": user}\n",
        "#         ]\n",
        "#     ).choices[0].message.content\n",
        "#     clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M | re.I)\n",
        "#     start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "#     return json.loads(clean[start:end+1])\n",
        "\n",
        "# def translate_to_spanish(english_text: str) -> str:\n",
        "#     \"\"\"Translate English medical text to Spanish.\"\"\"\n",
        "#     prompt = f\"Translate this English medical text into clear, neutral Spanish:\\n{english_text}\"\n",
        "#     return client.chat.completions.create(\n",
        "#         model=\"gpt-4o-mini\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "#     ).choices[0].message.content.strip()\n",
        "\n",
        "# def text_to_speech_spanish(text: str, filename: str, voice=\"alloy\"):\n",
        "#     \"\"\"Convert Spanish text to speech (TTS).\"\"\"\n",
        "#     os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "#     with client.audio.speech.with_streaming_response.create(\n",
        "#         model=\"gpt-4o-mini-tts\", voice=voice, input=text\n",
        "#     ) as response:\n",
        "#         response.stream_to_file(filename)\n",
        "#     print(f\"🔊 Saved Spanish audio: {filename}\")\n",
        "#     return filename\n",
        "\n",
        "# # ================================================================\n",
        "# # 3️⃣ MAIN PIPELINE\n",
        "# # ================================================================\n",
        "# def run_full_pipeline(csv_path: str, audio_folder: str, audio_files: list[str]):\n",
        "#     \"\"\"\n",
        "#     Full workflow:\n",
        "#       1. Transcribe + translate Spanish audio questions\n",
        "#       2. Use English translation for GPT-4 analysis\n",
        "#       3. Translate answers to Spanish\n",
        "#       4. Convert Spanish answers to speech\n",
        "#       5. Save all results to CSV\n",
        "#     \"\"\"\n",
        "#     # Step 1 – Transcription + translation\n",
        "#     trans_csv = os.path.join(CSV_OUTPUT_FOLDER, \"audio_translations.csv\")\n",
        "#     trans_df = process_and_translate_audio(audio_folder, audio_files, trans_csv)\n",
        "\n",
        "#     # Step 2 – Load BP dataset\n",
        "#     df_bp = pd.read_csv(csv_path)\n",
        "#     csv_block = df_bp.to_csv(index=False)\n",
        "\n",
        "#     results = []\n",
        "#     for i, row in trans_df.iterrows():\n",
        "#         q_num, q_en = row[\"question_number\"], row[\"english_translation\"]\n",
        "#         print(f\"\\n🔹 Q{q_num}: {q_en}\")\n",
        "\n",
        "#         try:\n",
        "#             # Step 3 – GPT Analysis\n",
        "#             ans = ask_gpt(q_en, csv_block)\n",
        "#             ans_en = ans.get(\"answer\", \"\").strip()\n",
        "\n",
        "#             # Step 4 – Translate answer → Spanish\n",
        "#             ans_es = translate_to_spanish(ans_en)\n",
        "\n",
        "#             # Step 5 – Convert answer → audio\n",
        "#             audio_file = os.path.join(AUDIO_OUTPUT_FOLDER, f\"answer_{q_num}_es.wav\")\n",
        "#             text_to_speech_spanish(ans_es, audio_file)\n",
        "\n",
        "#             results.append({\n",
        "#                 \"question_number\": q_num,\n",
        "#                 \"audio_file_in\": row[\"audio_file\"],\n",
        "#                 \"spanish_question\": row[\"spanish_transcription\"],\n",
        "#                 \"english_question\": q_en,\n",
        "#                 \"english_answer\": ans_en,\n",
        "#                 \"spanish_answer\": ans_es,\n",
        "#                 \"audio_answer_file\": audio_file,\n",
        "#                 \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "#             })\n",
        "\n",
        "#             print(f\"✅ Completed Q{q_num}\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"❌ Error for Q{q_num}: {e}\")\n",
        "\n",
        "#     # Step 6 – Save final combined results\n",
        "#     final_csv = os.path.join(CSV_OUTPUT_FOLDER, \"final_pipeline_results.csv\")\n",
        "#     out_df = pd.DataFrame(results)\n",
        "#     out_df.to_csv(final_csv, index=False)\n",
        "#     print(f\"\\n✅ All results (audio + translations + analysis) saved to {final_csv}\")\n",
        "#     return out_df\n",
        "\n",
        "# # ================================================================\n",
        "# # 4️⃣ RUN PIPELINE\n",
        "# # ================================================================\n",
        "# csv_path = os.path.join(BASE_PATH, \"Data\", \"synthetic_bp_one_person.csv\")\n",
        "\n",
        "# results_df = run_full_pipeline(csv_path, AUDIO_INPUT_FOLDER, audio_files)\n",
        "# display(results_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "mkwr3OTAcCBB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this pipeline has the WER /CER and sentence error rate computation\n",
        "\n",
        "# ================================================================\n",
        "# HEALTH TEQUITY CASE – COMPLETE PIPELINE\n",
        "# Audio → Transcription → WER → LLM → Translation → TTS\n",
        "# ================================================================\n",
        "\n",
        "import os, json, re, pandas as pd\n",
        "import whisper\n",
        "from openai import OpenAI\n",
        "from jiwer import wer, mer, wil\n",
        "from jiwer import process_words\n",
        "import Levenshtein\n",
        "\n",
        "# ================================================================\n",
        "# 0️⃣ CONFIGURATION\n",
        "# ================================================================\n",
        "BASE_PATH = \"/content/drive/MyDrive/health-tequity-case\"\n",
        "\n",
        "# Define key folders\n",
        "AUDIO_INPUT_FOLDER = os.path.join(BASE_PATH, \"Input_Audio_Files\")\n",
        "AUDIO_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"audio_out\")\n",
        "CSV_OUTPUT_FOLDER = os.path.join(BASE_PATH, \"data\", \"csv_results\")\n",
        "\n",
        "# Ensure output folders exist\n",
        "os.makedirs(AUDIO_OUTPUT_FOLDER, exist_ok=True)\n",
        "os.makedirs(CSV_OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Check input folder\n",
        "if not os.path.exists(AUDIO_INPUT_FOLDER):\n",
        "    raise FileNotFoundError(f\"❌ Input folder not found: {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "audio_files = [f for f in os.listdir(AUDIO_INPUT_FOLDER) if f.lower().endswith(('.wav', '.mp3', '.m4a'))]\n",
        "if not audio_files:\n",
        "    raise ValueError(f\"❌ No audio files found in {AUDIO_INPUT_FOLDER}\")\n",
        "\n",
        "print(f\"✅ Found {len(audio_files)} audio file(s): {audio_files}\")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 1️⃣ AUDIO → SPANISH TRANSCRIPTION + ENGLISH TRANSLATION\n",
        "# ================================================================\n",
        "def transcribe_spanish_audio(model, audio_path):\n",
        "    print(f\"🎧 Transcribing: {audio_path}\")\n",
        "    result = model.transcribe(audio_path, language=\"spanish\", task=\"transcribe\", verbose=False)\n",
        "    return result[\"text\"].strip(), result[\"language\"]\n",
        "\n",
        "def translate_spanish_to_english(spanish_text: str) -> str:\n",
        "    \"\"\"Translate Spanish transcription to English.\"\"\"\n",
        "    prompt = f\"Translate the following Spanish medical question into clear English:\\n\\n{spanish_text}\"\n",
        "    result = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return result.choices[0].message.content.strip()\n",
        "\n",
        "def process_and_translate_audio(audio_folder, audio_files, output_csv):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    all_results = []\n",
        "\n",
        "    print(\"\\n🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\\n\" + \"=\"*60)\n",
        "    for i, audio_file in enumerate(audio_files, 1):\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(f\"⚠️ {audio_file} not found, skipping...\")\n",
        "            continue\n",
        "\n",
        "        spanish_text, detected_lang = transcribe_spanish_audio(model, audio_path)\n",
        "        english_text = translate_spanish_to_english(spanish_text)\n",
        "\n",
        "        all_results.append({\n",
        "            \"audio_file\": audio_file,\n",
        "            \"spanish_transcription\": spanish_text,\n",
        "            \"english_translation\": english_text,\n",
        "            \"language_detected\": detected_lang\n",
        "        })\n",
        "\n",
        "        print(f\"\\n[{i}] {audio_file}\")\n",
        "        print(f\"🇪🇸 {spanish_text}\")\n",
        "        print(f\"🇬🇧 {english_text}\")\n",
        "\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ Transcriptions + translations saved to {output_csv}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2️⃣ ASR EVALUATION (WER, CER, SER)\n",
        "# ================================================================\n",
        "def compute_cer(reference: str, hypothesis: str) -> float:\n",
        "    \"\"\"Character Error Rate (CER).\"\"\"\n",
        "    reference, hypothesis = reference.strip(), hypothesis.strip()\n",
        "    if not reference:\n",
        "        return 1.0 if hypothesis else 0.0\n",
        "    return Levenshtein.distance(reference, hypothesis) / len(reference)\n",
        "\n",
        "def compute_sentence_error(reference: str, hypothesis: str) -> int:\n",
        "    \"\"\"Sentence Error Rate (SER).\"\"\"\n",
        "    return 0 if reference.strip() == hypothesis.strip() else 1\n",
        "\n",
        "def evaluate_asr_performance(ground_truth_csv, transcribed_csv, output_csv):\n",
        "    if not os.path.exists(ground_truth_csv):\n",
        "        raise FileNotFoundError(f\"❌ Missing GT file: {ground_truth_csv}\")\n",
        "    if not os.path.exists(transcribed_csv):\n",
        "        raise FileNotFoundError(f\"❌ Missing transcription file: {transcribed_csv}\")\n",
        "\n",
        "    gt_df = pd.read_csv(ground_truth_csv)\n",
        "    tr_df = pd.read_csv(transcribed_csv)\n",
        "\n",
        "    gt_df.columns = [c.lower().strip() for c in gt_df.columns]\n",
        "    tr_df.columns = [c.lower().strip() for c in tr_df.columns]\n",
        "\n",
        "    df = pd.merge(gt_df, tr_df, on=\"audio_file\", how=\"inner\")\n",
        "\n",
        "    print(f\"\\n🎯 Evaluating {len(df)} files for ASR metrics...\\n\")\n",
        "\n",
        "    results = []\n",
        "    for _, row in df.iterrows():\n",
        "        ref = str(row[\"ground_truth\"])\n",
        "        hyp = str(row[\"spanish_transcription\"])\n",
        "\n",
        "        m = wer(ref, hyp)\n",
        "        cer = compute_cer(ref, hyp)\n",
        "        ser = compute_sentence_error(ref, hyp)\n",
        "\n",
        "        results.append({\n",
        "            \"audio_file\": row[\"audio_file\"],\n",
        "            \"ground_truth\": ref,\n",
        "            \"whisper_transcription\": hyp,\n",
        "            \"WER\": round(m[\"wer\"], 4),\n",
        "            \"Substitutions\": m[\"substitutions\"],\n",
        "            \"Deletions\": m[\"deletions\"],\n",
        "            \"Insertions\": m[\"insertions\"],\n",
        "            \"CER\": round(cer, 4),\n",
        "            \"SER\": ser\n",
        "        })\n",
        "\n",
        "        print(f\"🎧 {row['audio_file']} → WER={m['wer']:.3f}, CER={cer:.3f}, SER={ser}\")\n",
        "\n",
        "    out_df = pd.DataFrame(results)\n",
        "    out_df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ ASR metrics saved to {output_csv}\")\n",
        "    return out_df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 3️⃣ GPT DATA ANALYSIS + TRANSLATION + TTS\n",
        "# ================================================================\n",
        "SYSTEM = \"\"\"\n",
        "You are a careful data analyst.\n",
        "You receive a synthetic blood pressure dataset with columns: date, age, sex, systolic, diastolic.\n",
        "Do ALL analysis yourself using ONLY the CSV provided.\n",
        "Answer questions like: daily readings, averages, trends, comparisons, etc.\n",
        "Return JSON:\n",
        "{ \"answer\": \"<English answer>\", \"computed_fields\": { \"numeric values used\" } }\n",
        "\"\"\"\n",
        "\n",
        "def ask_gpt(question_en, csv_block):\n",
        "    user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0,\n",
        "        messages=[{\"role\": \"system\", \"content\": SYSTEM}, {\"role\": \"user\", \"content\": user}]\n",
        "    ).choices[0].message.content\n",
        "    clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M | re.I)\n",
        "    start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "    return json.loads(clean[start:end+1])\n",
        "\n",
        "def translate_to_spanish(english_text):\n",
        "    prompt = f\"Translate this English medical answer into clear, neutral Spanish:\\n{english_text}\"\n",
        "    return client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    ).choices[0].message.content.strip()\n",
        "\n",
        "def text_to_speech_spanish(text, filename, voice=\"alloy\"):\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=\"gpt-4o-mini-tts\", voice=voice, input=text\n",
        "    ) as response:\n",
        "        response.stream_to_file(filename)\n",
        "    print(f\"🔊 Saved Spanish audio: {filename}\")\n",
        "    return filename\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 4️⃣ MAIN PIPELINE\n",
        "# ================================================================\n",
        "def run_full_pipeline(csv_path, audio_folder, audio_files):\n",
        "    # Step 1 — Transcribe and Translate Spanish Audio\n",
        "    trans_csv = os.path.join(CSV_OUTPUT_FOLDER, \"audio_translations.csv\")\n",
        "    trans_df = process_and_translate_audio(audio_folder, audio_files, trans_csv)\n",
        "\n",
        "    # Step 2 — Evaluate ASR (WER, CER, SER)\n",
        "    gt_csv = os.path.join(audio_folder, \"ground_truth.csv\")\n",
        "    asr_csv = os.path.join(CSV_OUTPUT_FOLDER, \"asr_metrics.csv\")\n",
        "    asr_df = evaluate_asr_performance(gt_csv, trans_csv, asr_csv)\n",
        "\n",
        "    # Step 3 — Load Blood Pressure Data\n",
        "    df_bp = pd.read_csv(csv_path)\n",
        "    csv_block = df_bp.to_csv(index=False)\n",
        "\n",
        "    results = []\n",
        "    for i, row in trans_df.iterrows():\n",
        "        q_num = i + 1\n",
        "        q_en = row[\"english_translation\"]\n",
        "        print(f\"\\n🔹 Q{q_num}: {q_en}\")\n",
        "\n",
        "        try:\n",
        "            ans = ask_gpt(q_en, csv_block)\n",
        "            ans_en = ans.get(\"answer\", \"\").strip()\n",
        "            ans_es = translate_to_spanish(ans_en)\n",
        "\n",
        "            audio_file = os.path.join(AUDIO_OUTPUT_FOLDER, f\"answer_{q_num}_es.wav\")\n",
        "            text_to_speech_spanish(ans_es, audio_file)\n",
        "\n",
        "            results.append({\n",
        "                \"question_number\": q_num,\n",
        "                \"audio_file_in\": row[\"audio_file\"],\n",
        "                \"spanish_question\": row[\"spanish_transcription\"],\n",
        "                \"english_question\": q_en,\n",
        "                \"english_answer\": ans_en,\n",
        "                \"spanish_answer\": ans_es,\n",
        "                \"audio_answer_file\": audio_file,\n",
        "                \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "            })\n",
        "            print(f\"✅ Completed Q{q_num}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error Q{q_num}: {e}\")\n",
        "\n",
        "    # Step 4 — Save Final Results\n",
        "    final_csv = os.path.join(CSV_OUTPUT_FOLDER, \"final_pipeline_results.csv\")\n",
        "    pd.DataFrame(results).to_csv(final_csv, index=False)\n",
        "    print(f\"\\n✅ All results saved to {final_csv}\")\n",
        "    return results\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 5️⃣ RUN\n",
        "# ================================================================\n",
        "csv_path = os.path.join(BASE_PATH, \"Data\", \"synthetic_bp_one_person.csv\")\n",
        "run_full_pipeline(csv_path, AUDIO_INPUT_FOLDER, audio_files)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "24fc174e-c225-4e9a-acd4-f58739516d1b",
        "id": "ugfC9NC-ahAx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found 4 audio file(s): ['q2_es.wav', 'q3_es.wav', 'q4_es.wav', 'q1_es.wav']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 62.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\n",
            "============================================================\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:04<00:00, 66.77frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] q2_es.wav\n",
            "🇪🇸 ¿Cuáles fueron los valores de la última semana?\n",
            "🇬🇧 What were the values from the last week?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 261/261 [00:02<00:00, 103.29frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2] q3_es.wav\n",
            "🇪🇸 ¿Cuál es la tendencia de mis valores?\n",
            "🇬🇧 \"What is the trend of my values?\"\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398/398 [00:02<00:00, 147.75frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3] q4_es.wav\n",
            "🇪🇸 ¿Cuáles son los rango normales para una persona como yo?\n",
            "🇬🇧 What are the normal ranges for a person like me?\n",
            "🎧 Transcribing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 324/324 [00:04<00:00, 66.42frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4] q1_es.wav\n",
            "🇪🇸 ¿Cuáles son mis valores de presión arterial hoy?\n",
            "🇬🇧 What are my blood pressure readings today?\n",
            "\n",
            "✅ Transcriptions + translations saved to /content/drive/MyDrive/health-tequity-case/data/csv_results/audio_translations.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "❌ Missing GT file: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/ground_truth.csv",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-2555266208.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"synthetic_bp_one_person.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m \u001b[0mrun_full_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUDIO_INPUT_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-23-2555266208.py\u001b[0m in \u001b[0;36mrun_full_pipeline\u001b[0;34m(csv_path, audio_folder, audio_files)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mgt_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ground_truth.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0masr_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_OUTPUT_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"asr_metrics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0masr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_asr_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masr_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# Step 3 — Load Blood Pressure Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-23-2555266208.py\u001b[0m in \u001b[0;36mevaluate_asr_performance\u001b[0;34m(ground_truth_csv, transcribed_csv, output_csv)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_asr_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscribed_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"❌ Missing GT file: {ground_truth_csv}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscribed_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"❌ Missing transcription file: {transcribed_csv}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: ❌ Missing GT file: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/ground_truth.csv"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   !pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI7cACt9atfo",
        "outputId": "103f38c6-7fda-407d-b1ab-663505b0e844"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.14.1)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Templates + GPT call (JSON output)**"
      ],
      "metadata": {
        "id": "q_Jyz09XejJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json, re\n",
        "# from openai import OpenAI\n",
        "\n",
        "# client = OpenAI(api_key=api_key)\n",
        "\n",
        "# TEMPLATES = {\n",
        "#     \"today\":         \"Your systolic blood pressure was {sys} mm of Hg and your diastolic blood pressure was {dia} mm of Hg.\",\n",
        "#     \"last_week\":     \"Over the last week, your systolic blood pressure has averaged {sys_avg} mm of Hg and your diastolic blood pressure has averaged {dia_avg} mm of Hg.\",\n",
        "#     \"trend_month\":   \"The trend for the values over the last month has been {trend} average values of your systolic blood pressure and diastolic blood pressure.\",\n",
        "#     \"normal_ranges\": \"While each person’s normal range should be discussed with their physician, literature suggests that for a {sex} aged {age} years, systolic and diastolic blood pressure can typically be expected to be {sys_norm} mm Hg and {dia_norm} mm Hg respectively. This information was retrieved from {reference}.\"\n",
        "# }\n",
        "\n",
        "# SYSTEM = \"\"\"You are a careful data analyst.\n",
        "# Do ALL analysis yourself using ONLY the CSV provided by the user.\n",
        "# Interpret columns: date, age, sex, systolic, diastolic.\n",
        "# - \"Today\" = most recent row by date.\n",
        "# - \"Last week\" = last 7 rows by date (including the most recent).\n",
        "# - \"Trend over the last month\" = last 30 rows; return one of: increasing / decreasing / stable.\n",
        "# - If a specific date is mentioned (e.g., 'on October 1'), return that date’s values if present.\n",
        "# Return STRICT JSON ONLY:\n",
        "# {\n",
        "#  \"template\": \"today\"|\"last_week\"|\"trend_month\"|\"normal_ranges\",\n",
        "#  \"fields\": {...},   # only the slots the chosen template needs (e.g., sys, dia, sys_avg, dia_avg, trend, age, sex, sys_norm, dia_norm, reference, date)\n",
        "#  \"final_text\": \"one sentence exactly following the chosen template with mm of Hg units\"\n",
        "# }\n",
        "# No extra prose. JSON only.\n",
        "# \"\"\"\n",
        "\n",
        "# def ask_gpt(question_en: str, csv_block: str) -> dict:\n",
        "#     user = f\"CSV:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\\n\\nReturn JSON only.\"\n",
        "#     resp = client.chat.completions.create(\n",
        "#         model=\"gpt-4o\",     # or \"gpt-4o-mini\" for lower cost\n",
        "#         temperature=0,\n",
        "#         messages=[\n",
        "#             {\"role\":\"system\",\"content\":SYSTEM},\n",
        "#             {\"role\":\"system\",\"content\":\"Templates:\\n\" + json.dumps(TEMPLATES)},\n",
        "#             {\"role\":\"user\",\"content\":user}\n",
        "#         ]\n",
        "#     ).choices[0].message.content\n",
        "\n",
        "#     # Strip possible code fences and parse only the JSON blob\n",
        "#     clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M|re.I)\n",
        "#     start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "#     return json.loads(clean[start:end+1])\n",
        "\n"
      ],
      "metadata": {
        "id": "tIP2Nmy8LQ48"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run the 4 required question and save results**"
      ],
      "metadata": {
        "id": "-DrRxc51e6Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd, os\n",
        "\n",
        "# questions = [\n",
        "#     \"What are my systolic and diastolic blood pressures today?\",\n",
        "#     \"What were the values over the last week?\",\n",
        "#     \"What is the trend of the values over the last month?\",\n",
        "#     \"What are the normal ranges for a person like me?\",\n",
        "#     # Optional extension:\n",
        "#     \"What were my blood pressure values on October 1?\"\n",
        "# ]\n",
        "\n",
        "# rows = []\n",
        "# for q in questions:\n",
        "#     obj = ask_gpt(q, csv_text)\n",
        "#     rows.append({\n",
        "#         \"question\": q,\n",
        "#         \"template\": obj.get(\"template\"),\n",
        "#         \"fields\": json.dumps(obj.get(\"fields\", {}), ensure_ascii=False),\n",
        "#         \"answer_en\": obj.get(\"final_text\")\n",
        "#     })\n",
        "#     print(f\"\\nQ: {q}\\nA: {obj.get('final_text')}\")\n",
        "\n",
        "# # os.makedirs(\"/content/drive/MyDrive/health-tequity-case\", exist_ok=True)\n",
        "# out_path = \"/content/drive/MyDrive/health-tequity-case/Data/llm_answers_en_colab.csv\"\n",
        "# pd.DataFrame(rows).to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "# print(f\"\\n✅ Saved: {out_path}\")\n"
      ],
      "metadata": {
        "id": "A63bKwRve5qA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT-to-Speech(**TTS**)"
      ],
      "metadata": {
        "id": "u2i804KL2iY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gTTS\n"
      ],
      "metadata": {
        "id": "1ki44Jvt22gW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gtts import gTTS\n",
        "# import os\n",
        "\n",
        "# # Spanish text (your model’s translated output)\n",
        "# spanish_answer = \"Su presión arterial sistólica fue de 135 milímetros de mercurio y su presión diastólica fue de 88.\"\n",
        "\n",
        "# # Create TTS object (language code 'es' = Spanish)\n",
        "# tts = gTTS(text=spanish_answer, lang='es')\n",
        "\n",
        "# # Save the output file\n",
        "# output_path = \"data/output_q1_es.wav\"\n",
        "# tts.save(output_path)\n",
        "\n",
        "# print(f\"✅ Spanish audio saved: {output_path}\")\n"
      ],
      "metadata": {
        "id": "6vuVUaMfMGJ1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KlQHSNIR3IEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}